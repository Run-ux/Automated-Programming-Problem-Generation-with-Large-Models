### **PYTASKSYN：基于 LLM 专家和学生智能体的高质量编程任务合成技术**

**论文核心思想：**

该论文介绍了一种名为 **PYTASKSYN** 的新颖合成技术，旨在通过模拟不同角色的 LLM 智能体（专家和学生）来生成高质量的编程任务并自动验证其质量。其核心思想是将复杂的任务合成过程分解为多个阶段，并由专门的智能体负责，以克服现有 AI 生成任务在质量上与人类专家任务之间的差距。

**面临的问题与挑战：**

尽管生成式 AI 在编程任务生成方面取得了进展，但 AI 生成的任务仍存在显著的质量问题，例如：

1. **概念不一致：** 任务可能与目标编程概念不符。
2. **难以理解：** 任务描述对学生来说可能难以理解。
3. **关键错误：** 包含不正确的测试用例。
4. **需要人工干预：** 现有方法通常需要人工教师进行验证，增加了工作量。
5. **单智能体验证局限：** 单一生成式智能体在自我修正和全面验证方面存在不足。

**PYTASKSYN 解决方案概览 (Pipeline Overview)：**

PYTASKSYN 采用**多智能体（Multi-agent）**方法，将任务合成过程分为两个主要阶段：

1. **生成阶段 (Stage 1 - Generation)：**

   - **角色：** **SIMEXPERT** 智能体（基于 GPT-40 强大的生成模型）。
   - **任务：** 根据输入的“主题 (theme)”和“编程概念 (programming concepts)”生成一个编程任务（包括任务描述 `Tdesc` 和测试套件 `Ttests`）。
   - **内部检查：** 在此阶段，SIMEXPERT 还会生成一个参考解决方案，并用 `Ttests` 进行一致性检查。如果测试不通过，任务被视为无效，不会进入下一阶段。

2. **验证阶段 (Stage 2 - Validation)：**

   - **目标：** 对生成的任务进行质量保证，决定其是否符合提供给学生的标准。

   - 多智能体协同：

      

     该阶段由两种类型的模拟智能体协同完成：

     - 2a. SIMTUTOR (模拟导师) 验证：
       - **角色：** 模拟人类导师（基于 GPT-40 强大的生成模型）。
       - 任务：
         - **解决任务：** 编写一个解决方案代码 `C*` 来解决任务，这模仿了人类专家评估任务的思维链 (Chain-of-Thought) 过程。
         - **评估测试套件：** 验证 `Ttests` 是否能正确验证 `C*`，并检查 `C*` 的每一行是否都被 `Ttests` 覆盖。
         - **评估上下文相关性：** 评估任务是否有效整合了给定主题和编程概念（打分 0 或 1）。如果智能体试图通过直接使用输入-输出对作弊，则相关性得分为 0。
     - 2b. SIMSTUDENT (模拟学生) 验证：
       - **角色：** 模拟学生群体（使用 GPT-40-mini 较弱的生成模型，更适合模拟学生视角）。
       - **任务：** 评估任务描述 `Tdesc` 的**可理解性 (comprehensibility)**。
       - **机制：** 模拟多个学生智能体（实验中为 20 个）尝试解决任务。如果大多数学生智能体（默认阈值 50%）无法解决任务，则认为 `Tdesc` 缺乏清晰度或关键信息。

   - **重试机制：** 如果任务未能通过验证阶段，PYTASKSYN 会重试生成和验证过程，最多 N 次。

**关键贡献 (Main Contributions)：**

1. **多阶段分解：** 强调将编程任务合成分解为多个阶段的有效性，并引入 PYTASKSYN 技术，利用模拟的专家、导师和学生智能体，每个智能体负责合成过程中的特定阶段。
2. **显著提高任务质量：** 通过对 Python 编程任务合成的广泛评估，证明 PYTASKSYN 显著提高了合成任务的质量，同时保持了可观的覆盖率。消融研究（Ablation Study）表明，每个专业化智能体在验证流程中都至关重要（SIMTUTOR 提升测试套件质量和上下文相关性，SIMSTUDENT 提升任务可理解性）。
3. **用户研究与实际应用：** 开发了一个公开的 Web 应用程序，并进行了用户研究，结果显示 PYTASKSYN 生成的高质量编程任务与专家设计的任务相当，同时显著降低了工作量和成本，并且比在线资源中的任务更具吸引力。

**性能指标 (Evaluation Metrics)：**

- **Coverage (覆盖率)：** 技术提供编程任务给学生的百分比。
- **Precision (准确率)：** 提供给学生的编程任务是高质量任务的百分比。
- **Q-Overall (总体质量)：** 专家对任务的整体质量评分。
- **Test suite correctness and coverage (测试套件正确性和覆盖率)：** 测试套件是否正确验证解决方案并覆盖所有相关案例。
- **Context relevance (上下文相关性)：** 任务是否准确反映输入的主题和编程概念。
- **Comprehensibility (可理解性)：** 任务描述是否为学生编写解决方案提供了足够的信息。

**总结：**

PYTASKSYN 通过其创新的多智能体、多阶段验证框架，成功地解决了 AI 生成编程任务的质量问题。它不仅提升了任务的整体质量、测试套件的准确性和可理解性，还显著降低了任务创建成本和时间，为教育领域自动化高质量编程内容生成提供了有效途径。