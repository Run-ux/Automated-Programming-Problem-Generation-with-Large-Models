**AutoCode: 大语言模型作为竞技编程出题者**

这篇论文介绍了 **AutoCode**，一个创新的闭环多角色框架，旨在利用大型语言模型（LLMs）自动化竞技编程问题的创建和评估全生命周期。该系统通过高度可靠的测试用例生成和新颖高质量的问题生成，显著提升了竞技编程基准测试的严谨性，并为 LLM 在复杂编程任务中的应用提供了重要验证。

### 核心贡献

AutoCode 的主要贡献体现在以下两个方面：

1. **现有问题的先进测试用例生成：**
   - AutoCode 引入了一个增强的 **Validator-Generator-Checker (VGC)** 框架，用于生成高质量的测试用例。
   - 该框架在 7538 个问题的基准测试中，与官方判定的**一致性高达 91.1%**，显著优于现有方法的 72-81%。
   - 它将**误报率 (FPR)** 大幅降低至 3.7%，将**漏报率 (FNR)** 降低至 14.1%，相比现有最佳方法下降了约 50%。
   - 即使在更具挑战性的 720 个 Codeforces 问题基准上（包含复杂交互式问题），AutoCode 仍保持了 **98.7% 的一致性**。
2. **新颖高质量的问题生成：**
   - AutoCode 开创了一种系统化的新问题生成流程，通过**双重验证机制**确保生成问题的正确性和质量。
   - 该流程以一个“种子问题”为起点，LLM 生成新的问题陈述、一个高效的参考解决方案（`std.cpp`）和一个简单的暴力解决方案（`brute.cpp`）。
   - 通过将两种解决方案与生成的测试用例进行交叉验证，确保其输出一致，从而过滤掉 27% 容易出错的问题，将 LLM 提供的参考解决方案的正确率从 86% 提高到 94%。
   - 人类专家（Grandmaster 级别）评估结果显示，AutoCode 成功生成了被认为具有竞赛质量的新颖问题。

### AutoCode 框架详解

AutoCode 框架的核心是一个**闭环的多角色 Validator-Generator-Checker (VGC) 结构**，并扩展加入了 Interactor 和双重验证协议。整个流程分为四个主要阶段：

1. **Create (创建)：**

   - 从一个“种子问题”开始，LLM 接收问题描述。
   - LLM 基于种子问题**创建（变体）新的问题**。
   - 同时，LLM 为新问题**生成参考解决方案 (Reference Solution)** 和**暴力解决方案 (Brute-force Solution)**。

2. **Generate (生成)：**

   - **Generator 程序**根据问题描述生成多样化的输入。
   - Generator 采用多策略，包括：
     - **小数据穷举 (Small Data Exhaustion)：** 覆盖边界条件和角点案例。
     - **随机和极端数据 (Randomized and Extreme Data)：** 压力测试，覆盖溢出、精度、哈希冲突和对抗性案例。
     - **TLE 诱导数据 (TLE-Inducing Data)：** 构造特定结构输入，以暴露时间复杂度不正确的解决方案。
   - 生成的测试用例会经过 Validator 过滤，确保输入合法。

3. **Validate (验证)：**

   - Validator (验证器)：

      

     核心功能是确保所有输入严格遵守问题约束，防止 malformed 数据导致正确程序失败（降低 FNR）。

     - **构建 Validator：** LLM 生成 3 个候选 Validator，并在一个包含 10 个有效输入和 30 个“近乎有效”非法输入的测试集上进行评估，选择表现最好的 Validator。

   - Checker (检查器)：

      

     负责比较提交程序的输出与参考解决方案的输出，并给出最终判定（降低 FPR）。

     - **构建 Checker：** LLM 生成 3 个候选 Checker，并在包含有效输入、可能错误输出、正确输出和预期判定的 40 个测试场景上评估，选择表现最好的 Checker。

   - Interactor (交互器)：

      

     针对交互式问题，通过与提交程序进行多轮对话来评估。

     - **构建 Interactor：** 通过对参考解决方案进行微小逻辑修改（生成“突变体”），然后 LLM 生成 3 个候选 Interactor。选择能成功通过正确参考解决方案，同时能使最多突变体失败的 Interactor。

   - **双重验证协议：** 新问题被接受的前提是，高效参考解决方案 (`std.cpp`) 的输出与暴力解决方案 (`brute.cpp`) 在所有测试用例上的输出均一致。暴力解决方案作为初始的“地面真值”，用于验证参考解决方案的正确性。

4. **Stress (压力测试)：**

   - 利用 Validator 过滤后的测试用例，运行参考解决方案和暴力解决方案，并由 Checker 验证输出。
   - 最终，通过 Checker 给出判决，确保问题的质量和测试用例的严谨性。

### 关键发现

论文还总结了 LLM 在问题生成方面的几个重要发现：

1. **LLM 能生成自身无法解决的可解问题：** 约 4.2% 的问题属于 LLM 能够创建但自身无法正确解决的范畴，这为模型自我改进提供了潜在机会。
2. **LLM 倾向于组合现有框架，强调知识和实现：** LLM 擅长通过重组和重新配置现有算法知识来创建新问题，而非提出全新的解题策略。它们更侧重于特定算法知识或复杂的实现细节。
3. **新颖问题具有更大的难度增益，中等难度种子问题效果最佳：** LLM 适应后问题的难度平均增加 334 Elo 分，新颖问题难度增加 498 分。中等难度种子问题最容易生成高质量问题。
4. **人类专家与 LLM 对问题质量和新颖性的判断几乎不相关：** 在问题质量和新颖性评估上，人类与 LLM 之间存在显著差异，表明仅依赖 LLM 自我评估不足以判断问题质量。
5. **生成问题的难度和难度增益是更好的问题质量指标：** 尽管 LLM 无法直接评估质量，但其对问题难度的预测能力可以作为间接衡量问题质量的代理信号。

### 局限性与未来工作

- **质量判断差距：** LLM 缺乏与人类对问题质量一致的判断力，目前仍需人工参与筛选高质量和新颖的问题。未来的方向是开发专门的“判断 LLM”来解决这一问题。
- **自动化自我改进的瓶颈：** 由于现有最强大的 LLM（如 GPT-5）是闭源的，且缺乏支持大规模强化学习的 API，阻碍了 AutoCode 实现完全自动化的自我改进闭环。
- **超越重组式创新：** LLM 目前主要通过组合现有算法来创建问题，未来需要探索新的提示策略或问题生成流程，以鼓励更大的概念性突破。此外，对于 LLM 能生成但自身无法解决的有效问题，需要开发可扩展的方法来识别它们，而不是依赖劳动密集型的人工检查。

------

总而言之，AutoCode 成功地将 LLM 部署为一个强大的竞技编程出题工具，不仅提高了测试用例生成的可靠性，还能够自主生成高质量、具有挑战性的新问题，为 LLM 在复杂编程领域的应用和自我改进开辟了新路径。