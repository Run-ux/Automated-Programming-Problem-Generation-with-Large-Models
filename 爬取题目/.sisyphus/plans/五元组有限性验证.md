# 五元组前四维有限性验证（I/C/O/V）工作计划

## TL;DR

> **Quick Summary**: 构建一个两阶段验证管线：Phase 1 用 Qwen 进行四维独立抽取与开放聚类，形成初步类目与饱和曲线；Phase 2 用封闭集合分类在全量数据上验证“有限可列”的覆盖率与收敛性。
>
> **Deliverables**:
> - I/C/O/V 四维的开放标签集与初步层级分类（Phase 1）
> - 饱和曲线与“有限可列”判定指标报告
> - 封闭集合分类器与全量覆盖率统计（Phase 2）
> - 断点续传的批处理抽取产物（JSON/CSV/日志）
>
> **Estimated Effort**: Medium
> **Parallel Execution**: YES - 2 waves
> **Critical Path**: 0 → 1 → 3 → 4 → 5

---

## Context

### Original Request
用户希望验证 Problem Schema 五元组前四个元素（输入结构 I、核心约束 C、目标函数 O、算法不变量 V）是否“有限且可列”。计划通过对 ~13K 题目进行 LLM 抽取、聚类和统计分析来验证这一命题，并改进方案使其更可靠。

### Interview Summary
**Key Discussions**:
- 采用“两阶段方法”：开放探索 → 受控验证
- 采用“维度独立抽取（I/C/O/V 分开）”而非一次性五元组抽取
- 采用 3x 采样 + 多数投票缓解 LLM 不一致
- 采用饱和曲线判定“有限可列”趋势
- 仅需 I/C/O/V 四维，不做 T 维
- 不需要单元测试，依靠 Agent-Executed QA 验证

**Research Findings**:
- 现有 Qwen 客户端与 prompt 模板：`{REPO_ROOT}/ICPC题目提取schema/icpc_schema_extractor/`（含 `qwen_client.py`, `schema_extract.py`, `models.py` 等 9 个 .py 文件，已验证存在）
- 已爬取数据结构：`{REPO_ROOT}/爬取题目/output/<platform>/index.json`（**注意：output/ 目录由爬虫运行后生成，当前磁盘上不存在。必须先运行 `python -m 爬取题目.main` 生成数据，或从其他机器拷贝**）
- Schema 五元组定义：`{REPO_ROOT}/爬取题目/schema五元组定义.md`（已验证存在，272 行）
- 现有 embedding/聚类研究：`{REPO_ROOT}/母题代码/embedding/`（已验证存在，含 `组会报告_母题Schema向量化研究.md`、`组会报告_Schema聚类与标签提取研究.md` 等 35 个文件）

> **路径说明**：`{REPO_ROOT}` = `D:\Automated-Programming-Problem-Generation-with-Large-Models\`。本计划的工作目录为 `{REPO_ROOT}/爬取题目/`，但引用的参考文件分布在仓库根目录下的多个子目录中。
>
> **重要：新模块目录**：`{REPO_ROOT}/finiteness_verification/` 是本项目的独立模块目录，位于仓库根目录下（与 `爬取题目/`、`母题代码/`、`ICPC题目提取schema/` 同级），所有新代码和输出均应放在此目录中。执行代理必须在 `{REPO_ROOT}` 下创建 `finiteness_verification/` 目录。

### Metis Review
**Identified Gaps (addressed)**:
- Constraints 字段在 CF/ICPC 多为空 → 必须从全文提取约束
- 缺少 Pilot Run → 增加 50 题试跑
- “有限可列”未量化 → 增加阈值定义（饱和率、拟合度）
- 多数投票缺归一化 → 增加同义词归一化层
- C 维度组合爆炸 → 明确“原子约束集有限”+组合可列
- 缺断点续传 → 增加可恢复的批处理与状态记录

---

## Work Objectives

### Core Objective
建立可复现的实验管线，用统计证据判断 I/C/O/V 是否“有限且可列”，并产出可解释的类目体系与覆盖率收敛报告。

### Concrete Deliverables
- 维度独立抽取结果（JSONL/CSV）
- 同义词归一化后的标签集合
- 饱和曲线与量化阈值报告
- Phase 2 封闭分类的覆盖率与“OTHER”收敛统计
- 全量运行报告（含平台分层对比）

### Definition of Done
- [ ] 50 题 Pilot Run 成功，输出结构/约束/目标/不变量四维字段完整率 ≥ 95%
- [ ] Phase 1 完成，形成每维初步类目集与饱和曲线
- [ ] Phase 2 完成，全量 13K 题目覆盖率统计与平台对比完成
- [ ] 量化判定阈值明确，并得出结论（支持/不支持“有限可列”）

### Must Have
- 维度独立抽取（I/C/O/V 分离）
- 3x 多数投票 + 同义词归一化
- 断点续传能力

### Must NOT Have (Guardrails)
- 不把 `constraints` 字段当作唯一信息来源
- 不进行一次性五元组抽取（降低一致性）
- 不在同一变更内同时“重构+功能修改”

---

## Verification Strategy (MANDATORY)

> **UNIVERSAL RULE: ZERO HUMAN INTERVENTION**
>
> 所有验收标准必须由执行代理通过命令或工具直接验证。

### Test Decision
- **Infrastructure exists**: NO
- **Automated tests**: None
- **Framework**: none

### Agent-Executed QA Scenarios (MANDATORY — ALL tasks)
所有任务均提供可运行的 QA 场景，使用 Bash 执行脚本/统计并保存证据。

---

## Execution Strategy

### Parallel Execution Waves

```
Wave 0 (Prerequisite):
└── Task 0: 确认爬取数据存在（如不存在则运行爬虫）

Wave 1 (After Wave 0, can run in parallel):
├── Task 1: 数据索引与分层采样准备
└── Task 2: Prompt/抽取协议设计 + Qwen 客户端

Wave 2 (Sequential, after Wave 1):
├── Task 3: Pilot Run + 归一化/投票 + 断点续传
├── Task 4: Phase 1 全量抽取 + 饱和曲线（depends on Task 3）
└── Task 5: Phase 2 封闭分类 + 覆盖率报告（depends on Task 4）
```

Critical Path: Task 0 → Task 1 → Task 3 → Task 4 → Task 5
Parallel Speedup: Task 1 ∥ Task 2 in Wave 1

### Dependency Matrix

| Task | Depends On | Blocks | Can Parallelize With |
|------|------------|--------|---------------------|
| 0 | None | 1, 2 | None |
| 1 | 0 | 3, 4, 5 | 2 |
| 2 | None* | 3, 4, 5 | 1 |
| 3 | 1, 2 | 4 | None |
| 4 | 3 | 5 | None |
| 5 | 4 | None | None |

*Task 2 不依赖爬取数据本身（仅设计 prompt），但其 QA 验证需要 Task 0 完成。

---

## TODOs

> Implementation + QA = ONE Task. No separate testing tasks.

- [x] 0. 前置条件：确认爬取数据存在

  **What to do**:
  - 检查 `{REPO_ROOT}/爬取题目/output/` 目录是否存在且包含 `luogu/index.json`、`codeforces/index.json`、`icpc/index.json`
  - 如果不存在，运行爬虫生成：`python -m 爬取题目.main luogu codeforces --max 500`（或从备份拷贝）
  - 确认每个 index.json 中题目数量（预期：luogu ~7903, codeforces ~2201, icpc ~3149）

  **Must NOT do**:
  - 不修改爬虫代码

  **Recommended Agent Profile**:
  - **Category**: `quick`
    - Reason: 仅需检查文件存在与可选运行爬虫
  - **Skills**: []

  **Parallelization**:
  - **Can Run In Parallel**: NO (前置条件)
  - **Blocks**: Task 1,2,3,4,5
  - **Blocked By**: None

  **References**:
  - `{REPO_ROOT}/爬取题目/config.py:10-15` - 输出目录定义（`OUTPUT_DIR = BASE_DIR / "output"`，子目录 `codeforces/`, `luogu/`, `icpc/`）
  - `{REPO_ROOT}/爬取题目/main.py` - 爬虫入口，支持 `--max` 参数限制抓取数量
  - `{REPO_ROOT}/爬取题目/common/models.py:ProblemText` - 每题输出字段定义

  **Acceptance Criteria**:
  - [ ] `{REPO_ROOT}/爬取题目/output/luogu/index.json` 存在且含 >0 条记录
  - [ ] `{REPO_ROOT}/爬取题目/output/codeforces/index.json` 存在且含 >0 条记录
  - [ ] `{REPO_ROOT}/爬取题目/output/icpc/index.json` 存在且含 >0 条记录

  **Agent-Executed QA Scenarios**:

  ```
  Scenario: 验证爬取数据目录与索引文件存在
    Tool: Bash
    Preconditions: 无
    Steps:
      1. python -c "import json; from pathlib import Path; root=Path(r'D:\Automated-Programming-Problem-Generation-with-Large-Models\爬取题目\output'); [print(f'{p.parent.name}: {len(json.loads(p.read_text(encoding=\"utf-8\")))} problems') for p in sorted(root.glob('*/index.json'))]"
      2. 断言输出包含 3 个平台且每个 >0
    Expected Result: 输出类似 "luogu: 7903 problems\ncodeforces: 2201 problems\nicpc: 3149 problems"
    Failure Indicators: FileNotFoundError 或任一平台数量为 0
    Evidence: .sisyphus/evidence/task-0-data-check.txt
  ```

  **Commit**: NO


- [x] 1. 数据索引与分层采样准备（三平台 + 样本集）

  **What to do**:
  - 从 `{REPO_ROOT}/爬取题目/output/<platform>/index.json` 读取题目索引
  - 生成 Stratified Sample（每平台 500 题）
  - 生成 Pilot Sample（全平台共 50 题，从 Stratified Sample 中随机抽取子集）
  - 生成数据清单（题目 ID、来源、md 文件路径）
  - 输出到 `{REPO_ROOT}/finiteness_verification/data/` 目录

  **Must NOT do**:
  - 不修改原始爬取数据

  **Recommended Agent Profile**:
  - **Category**: `unspecified-low`
    - Reason: 主要是数据读取与抽样脚本
  - **Skills**: []
  - **Skills Evaluated but Omitted**:
    - `playwright`: 非 UI 任务

  **Parallelization**:
  - **Can Run In Parallel**: YES (Wave 1)
  - **Blocks**: Task 3,4,5
  - **Blocked By**: Task 0

  **References**:
  - `{REPO_ROOT}/爬取题目/output/luogu/index.json` - Luogu 题目索引（每条含 problem_id, title, description, input, output, constraints, source, url, tags, difficulty）
  - `{REPO_ROOT}/爬取题目/output/codeforces/index.json` - Codeforces 题目索引（同上结构）
  - `{REPO_ROOT}/爬取题目/output/icpc/index.json` - ICPC 题目索引（同上结构）
  - `{REPO_ROOT}/爬取题目/common/models.py:8-16` - ProblemText 字段定义（pydantic BaseModel：problem_id, title, description, input, output, constraints, source, url, tags, difficulty）

  **WHY Each Reference Matters**:
  - index.json：直接数据源，脚本需按此结构解析
  - ProblemText：确保采样输出字段与原始数据模型一致

  **Acceptance Criteria**:
  - [ ] 生成 `{REPO_ROOT}/finiteness_verification/data/sample_pilot.json`（50 题）
  - [ ] 生成 `{REPO_ROOT}/finiteness_verification/data/sample_phase1.json`（~1500 题）
  - [ ] 每个样本条目包含：problem_id, source, title, input, output, constraints, description
  - [ ] 三平台分布均衡（每平台约 500 题 ±10%）

  **Agent-Executed QA Scenarios**:

  ```
  Scenario: 验证样本数量与分布
    Tool: Bash
    Preconditions: sample_pilot.json 与 sample_phase1.json 已生成
    Steps:
      1. python -c "import json; d=json.load(open(r'{REPO_ROOT}/finiteness_verification/data/sample_phase1.json',encoding='utf-8')); from collections import Counter; c=Counter(x['source'] for x in d); print(f'total={len(d)}'); [print(f'{k}: {v}') for k,v in c.items()]"
      2. 断言 total ≈ 1500，每平台 450-550
      3. python -c "import json; d=json.load(open(r'{REPO_ROOT}/finiteness_verification/data/sample_pilot.json',encoding='utf-8')); print(f'pilot={len(d)}')"
      4. 断言 pilot = 50
    Expected Result: 分布符合设计
    Failure Indicators: total 偏差 >10% 或某平台为 0
    Evidence: .sisyphus/evidence/task-1-sample-stats.txt
  ```

  **Commit**: YES
   - Message: `feat(finiteness): add stratified sampling script and sample data`
  - Files: `{REPO_ROOT}/finiteness_verification/data/*.json`, `{REPO_ROOT}/finiteness_verification/sample.py`


- [x] 2. 维度独立抽取协议与 Prompt 设计

  **What to do**:
  - 基于 `schema五元组定义.md` 编写 I/C/O/V 四个维度的独立 Prompt
  - 明确"约束必须从题面全文（description + input + output + constraints）提取"规则（不能只依赖 constraints 字段，因为 CF/ICPC 的 constraints 字段通常只含时间/内存限制）
  - 设计输出 JSON Schema（每维单独结构）
  - 明确 CLI/运行参数与输出目录约定（用于后续命令验收）
  - 复用现有 `qwen_client.py` 的 API 调用模式，新建本项目自己的客户端模块
  - Prompt 输出到 `{REPO_ROOT}/finiteness_verification/prompts/` 目录

  **Must NOT do**:
  - 不使用一次性五元组抽取（分四维独立提取）
  - 不直接 import `ICPC题目提取schema` 包（仅参考其模式，在本项目内重新实现）

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: Prompt 设计影响抽取一致性，需要仔细理解五元组语义
  - **Skills**: []

  **Parallelization**:
  - **Can Run In Parallel**: YES (Wave 1)
  - **Blocks**: Task 3,4,5
  - **Blocked By**: None

  **References**:

  **Pattern References (existing code to follow)**:
  - `{REPO_ROOT}/ICPC题目提取schema/icpc_schema_extractor/schema_extract.py:13-54` - Prompt 构造模式：`build_prompt()` 函数展示了如何将 schema 定义 + 题面组合成 system/user prompt，以及如何要求 JSON 输出
  - `{REPO_ROOT}/ICPC题目提取schema/icpc_schema_extractor/qwen_client.py:21-64` - API 调用模式：`QwenClient.chat_json()` 展示了 DashScope 兼容接口调用、重试逻辑、JSON 提取
  - `{REPO_ROOT}/ICPC题目提取schema/icpc_schema_extractor/models.py:19-25` - `SchemaOutput` 模型展示了五元组的 JSON 输出结构约定

  **Documentation References (specs and requirements)**:
  - `{REPO_ROOT}/爬取题目/schema五元组定义.md:37-187` - I/C/O/V 四维的精确语义定义、Python dataclass 结构、示例值。**这是 Prompt 设计的核心依据**

  **WHY Each Reference Matters**:
  - `schema_extract.py`：提供了已验证可用的 prompt 模板结构，新 prompt 应遵循相同的 system/user 分离模式
  - `qwen_client.py`：提供了已验证的 API 调用与 JSON 提取逻辑，新客户端应复用相同模式（DashScope endpoint、Bearer auth、retry、bracket-counting JSON 提取）
  - `schema五元组定义.md`：精确定义了四维的语义边界，prompt 必须忠实反映这些定义

  **Acceptance Criteria**:
  - [ ] 产出 4 个维度的 prompt 模板文件（I/C/O/V），位于 `{REPO_ROOT}/finiteness_verification/prompts/`
  - [ ] 每个 prompt 输出严格 JSON，且字段定义明确
  - [ ] Prompt 明确要求"从题面全文提取约束"（而非仅 constraints 字段）
  - [ ] 新建 `{REPO_ROOT}/finiteness_verification/qwen_client.py`（参考现有实现）

  **Agent-Executed QA Scenarios**:

  ```
  Scenario: Prompt 输出结构一致性检查
    Tool: Bash
    Preconditions: prompt 模板已生成，Qwen API Key 可用（DASHSCOPE_API_KEY 环境变量）
    Steps:
      1. 选取 pilot 样本中 2-3 道题
      2. 对每题分别运行 4 维 prompt 抽取
      3. 断言每维输出为合法 JSON
      4. 断言 I 维输出包含 "type" 字段
      5. 断言 C 维输出为数组，每项包含 "name" 和 "description"
      6. 断言 O 维输出包含 "type" 字段
      7. 断言 V 维输出包含 "name" 和 "description" 字段
    Expected Result: 4 维输出结构完整且可解析
    Failure Indicators: JSON 解析失败、必需字段缺失
    Evidence: .sisyphus/evidence/task-2-prompt-samples.json
  ```

  **Commit**: YES
  - Message: `feat(finiteness): design dimension-specific extraction prompts and qwen client`
  - Files: `{REPO_ROOT}/finiteness_verification/prompts/*.py`, `{REPO_ROOT}/finiteness_verification/qwen_client.py`


- [x] 3. Pilot Run + 归一化/投票机制 + 断点续传

  **What to do**:
  - 对 50 题进行 3x 抽取（每维 3 次）
  - 引入同义词归一化层（例如 array/1D array/整数数组）
  - 采用多数投票输出最终标签
  - 记录每题/每维的抽取版本、投票结果与置信度
  - 增加断点续传（中断可从已完成记录继续）
  - 统一输出目录结构（raw / normalized / voted / logs）
  - 限速策略显式化（复用 RateLimiter 或配置项）

  **Must NOT do**:
  - 不允许丢弃中间结果（必须可追溯）

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: 需要稳健的数据处理与恢复机制
  - **Skills**: []

  **Parallelization**:
  - **Can Run In Parallel**: NO (Wave 2)
  - **Blocked By**: Task 1,2
  - **Blocks**: Task 4,5

  **References**:

  **Pattern References (existing code to follow)**:
  - `{REPO_ROOT}/ICPC题目提取schema/icpc_schema_extractor/qwen_client.py:37-64` - `chat_json()` 方法的重试与 JSON 提取逻辑，新管线的 API 调用应复用此模式
  - `{REPO_ROOT}/ICPC题目提取schema/icpc_schema_extractor/schema_extract.py:57-72` - `extract_schema_for_problem()` 展示了如何调用 client、校验输出、容错保存

  **Infrastructure References**:
  - `{REPO_ROOT}/爬取题目/common/utils.py` - 检查是否包含 `RateLimiter` 类可复用（Metis 审查提到存在，执行时需先验证）

  **WHY Each Reference Matters**:
  - `qwen_client.py`：断点续传需要在此基础上增加状态追踪（哪些题目/维度/轮次已完成）
  - `utils.py`：如有 RateLimiter 可直接复用，无需重新实现限速逻辑

  **Acceptance Criteria**:
  - [ ] Pilot 输出：每题 4 维均有投票结果
  - [ ] 归一化词表可查看、可扩展
  - [ ] 断点续传测试：中断后继续不重复调用
  - [ ] 输出目录结构清晰、可复现

  **Agent-Executed QA Scenarios**:

  ```
  Scenario: Pilot Run 完整性
    Tool: Bash
    Preconditions: sample_pilot.json 已生成，DASHSCOPE_API_KEY 已设置
    Steps:
      1. python -m finiteness_verification.extract --input {REPO_ROOT}/finiteness_verification/data/sample_pilot.json --output {REPO_ROOT}/finiteness_verification/output/pilot/ --rounds 3
      2. python -c "import json,os; files=os.listdir(r'{REPO_ROOT}/finiteness_verification/output/pilot/voted/'); print(f'voted files: {len(files)}'); assert len(files)==50, f'Expected 50, got {len(files)}'"
      3. python -c "import json; d=json.load(open(r'{REPO_ROOT}/finiteness_verification/output/pilot/voted/sample_0.json',encoding='utf-8')); assert all(k in d for k in ['input_structure','core_constraints','objective','invariant']), f'Missing dimensions: {d.keys()}'"
    Expected Result: 50 题 × 4 维均有投票结果
    Failure Indicators: 文件数量 <50 或维度字段缺失
    Evidence: .sisyphus/evidence/task-3-pilot-output.json
  ```

  ```
  Scenario: 断点续传验证
    Tool: Bash
    Preconditions: Pilot 运行已部分完成（如 25/50 题）
    Steps:
      1. 在 {REPO_ROOT}/finiteness_verification/output/pilot/raw/ 中确认已有 25 题的原始输出
      2. 重新执行 python -m finiteness_verification.extract --input {REPO_ROOT}/finiteness_verification/data/sample_pilot.json --output {REPO_ROOT}/finiteness_verification/output/pilot/ --rounds 3 --resume
      3. 检查日志输出是否包含 "Skipping already completed" 类似信息
      4. 断言最终 API 调用次数 ≈ 25×4×3=300（而非 50×4×3=600）
    Expected Result: 续传成功，不重复调用
    Failure Indicators: 日志显示重复调用已完成题目
    Evidence: .sisyphus/evidence/task-3-resume-log.txt
  ```

  **Commit**: YES
  - Message: `feat(finiteness): pilot extraction with voting, normalization, and checkpoint resume`
  - Files: `{REPO_ROOT}/finiteness_verification/extract.py`, `{REPO_ROOT}/finiteness_verification/normalize.py`, `{REPO_ROOT}/finiteness_verification/vote.py`, `{REPO_ROOT}/finiteness_verification/output/pilot/**`


- [x] 4. Phase 1 全量抽取 + 饱和曲线

  **What to do**:
  - 对 1500 题样本执行 3x 抽取 + 投票
  - 汇总每维标签集合
  - 生成饱和曲线（新增标签数量 vs 题目数）
  - 建立“有限可列”量化标准（例如：R²>0.95 且最近 100 题新增率 <2%）

  **Must NOT do**:
  - 不跳过饱和度判断

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: 统计分析 + 数据处理
  - **Skills**: []

  **Parallelization**:
  - **Can Run In Parallel**: NO (Wave 2)
  - **Blocked By**: Task 3
  - **Blocks**: Task 5

  **References**:

  **Documentation References (prior research)**:
  - `{REPO_ROOT}/母题代码/embedding/组会报告_Schema聚类与标签提取研究.md` - 现有聚类与可视化经验（K-means, k=35, silhouette scoring），可参考其聚类评估方法论
  - `{REPO_ROOT}/母题代码/embedding/组会报告_母题Schema向量化研究.md` - Qwen text-embedding-v3 向量化经验，可参考其 embedding 方案（如果后续需要对标签做语义聚类）
  - `{REPO_ROOT}/母题代码/embedding/clustering_and_labeling.py` - 聚类代码实现参考
  - `{REPO_ROOT}/母题代码/embedding/output/clustering_report.txt` - 已有聚类结果与评估指标

  **WHY Each Reference Matters**:
  - 聚类报告：提供了 K 值选择与评估指标的先例经验
  - 聚类代码：可参考其可视化与报告生成模式

  **Acceptance Criteria**:
  - [ ] Phase 1 输出包含每维标签集合（`{REPO_ROOT}/finiteness_verification/output/phase1/labels_per_dimension.json`）
  - [ ] 饱和曲线生成并保存（`{REPO_ROOT}/finiteness_verification/output/phase1/saturation_curves/`）
  - [ ] 定义"有限可列"判定阈值并应用（例如 R²>0.95 且最近 100 题新增率 <2%）
  - [ ] 每维标签集合大小统计输出

  **Agent-Executed QA Scenarios**:

  ```
  Scenario: 饱和曲线生成与收敛判定
    Tool: Bash
    Preconditions: Phase 1 抽取完成
    Steps:
      1. python -m finiteness_verification.analyze --input {REPO_ROOT}/finiteness_verification/output/phase1/ --output {REPO_ROOT}/finiteness_verification/output/phase1/saturation_curves/
      2. 断言 saturation_curves/ 下存在 4 个图片文件（I/C/O/V 各一个）
      3. 断言 {REPO_ROOT}/finiteness_verification/output/phase1/saturation_curves/metrics.json 存在且包含每维的 R²、最后 100 题新增率、总标签数
      4. python -c "import json; m=json.load(open(r'{REPO_ROOT}/finiteness_verification/output/phase1/saturation_curves/metrics.json',encoding='utf-8')); [print(f\"{k}: labels={v['total_labels']}, R2={v['r_squared']:.3f}, tail_rate={v['tail_new_rate']:.3f}\") for k,v in m.items()]"
    Expected Result: 4 维指标均输出，I/O 维 R²>0.9，V 维可能较低
    Failure Indicators: 缺少维度、R² 为 NaN、图片未生成
    Evidence: .sisyphus/evidence/task-4-saturation-I.png, .sisyphus/evidence/task-4-saturation-C.png, .sisyphus/evidence/task-4-saturation-O.png, .sisyphus/evidence/task-4-saturation-V.png
  ```

  **Commit**: YES
  - Message: `feat(finiteness): phase1 full extraction with saturation curve analysis`
  - Files: `{REPO_ROOT}/finiteness_verification/analyze.py`, `{REPO_ROOT}/finiteness_verification/output/phase1/**`


- [ ] 5. Phase 2 封闭分类 + 覆盖率/收敛报告

  **What to do**:
  - 根据 Phase 1 输出整理封闭类目（I/C/O/V）
  - 设计封闭分类 prompt（含 OTHER 兜底）
  - 在全量 13K 题目运行分类
  - 计算覆盖率与 OTHER 收敛率
  - 进行平台间对比（Luogu/CF/ICPC）

  **Must NOT do**:
  - 不默认 OTHER 永远忽略，应统计趋势

  **Recommended Agent Profile**:
  - **Category**: `unspecified-high`
    - Reason: 需要全量统计与结论解释
  - **Skills**: []

  **Parallelization**:
  - **Can Run In Parallel**: NO (Wave 2)
  - **Blocked By**: Task 4

  **References**:

  **Data References**:
  - Phase 1 输出文件：`{REPO_ROOT}/finiteness_verification/output/phase1/labels_per_dimension.json` - 各维标签集合，作为封闭分类的候选列表
  - `{REPO_ROOT}/爬取题目/output/luogu/index.json` - Luogu 全量数据（~7903 题）
  - `{REPO_ROOT}/爬取题目/output/codeforces/index.json` - CF 全量数据（~2201 题）
  - `{REPO_ROOT}/爬取题目/output/icpc/index.json` - ICPC 全量数据（~3149 题）

  **WHY Each Reference Matters**:
  - Phase 1 标签集合：直接构成封闭分类的候选列表（+ OTHER 兜底）
  - 各平台 index.json：全量分类的输入数据源

  **Acceptance Criteria**:
  - [ ] 全量分类完成（~13K 题目，输出到 `{REPO_ROOT}/finiteness_verification/output/phase2/`）
  - [ ] 输出覆盖率统计（`{REPO_ROOT}/finiteness_verification/output/phase2/coverage_report.json`）
  - [ ] 输出 OTHER 收敛曲线（`{REPO_ROOT}/finiteness_verification/output/phase2/other_convergence/`）
  - [ ] 平台对比结果可视化（3 平台独立统计 + 合并统计）

  **Agent-Executed QA Scenarios**:

  ```
  Scenario: 全量覆盖率报告生成
    Tool: Bash
    Preconditions: 全量分类完成
    Steps:
      1. python -c "import json; r=json.load(open(r'{REPO_ROOT}/finiteness_verification/output/phase2/coverage_report.json',encoding='utf-8')); [print(f\"{dim}: coverage={v['coverage_rate']:.1%}, OTHER={v['other_rate']:.1%}\") for dim,v in r['per_dimension'].items()]"
      2. 断言每维 coverage_rate 字段存在
      3. 断言报告包含 per_platform 分层统计（luogu/codeforces/icpc）
      4. ls {REPO_ROOT}/finiteness_verification/output/phase2/other_convergence/ → 断言包含 4 个曲线图
    Expected Result: 覆盖率报告完整，含 4 维 × 3 平台数据
    Failure Indicators: coverage_report.json 缺少维度或平台数据
    Evidence: .sisyphus/evidence/task-5-coverage-report.json, .sisyphus/evidence/task-5-other-convergence-I.png
  ```

  ```
  Scenario: 跨平台收敛一致性检查
    Tool: Bash
    Preconditions: 覆盖率报告已生成
    Steps:
      1. python -c "import json; r=json.load(open(r'{REPO_ROOT}/finiteness_verification/output/phase2/coverage_report.json',encoding='utf-8')); pp=r['per_platform']; dims=['input_structure','core_constraints','objective','invariant']; [print(f\"{d}: luogu={pp['luogu'][d]['coverage_rate']:.1%}, cf={pp['codeforces'][d]['coverage_rate']:.1%}, icpc={pp['icpc'][d]['coverage_rate']:.1%}\") for d in dims]"
      2. 断言同一维度下各平台覆盖率差异 <15%（跨平台收敛一致性指标）
    Expected Result: 各平台在同一维度上的覆盖率趋于一致
    Failure Indicators: 某平台某维度覆盖率显著低于其他平台（差异 >15%）
    Evidence: .sisyphus/evidence/task-5-cross-platform.txt
  ```

  **Commit**: YES
  - Message: `feat(finiteness): closed-set classification and coverage analysis for full dataset`
  - Files: `{REPO_ROOT}/finiteness_verification/output/phase2/**`, `{REPO_ROOT}/finiteness_verification/classify.py`, `{REPO_ROOT}/finiteness_verification/report.py`


---

## Commit Strategy

仅在用户要求时提交。默认不自动 commit。

---

## Success Criteria

### Verification Commands
```bash
# Task 0: 检查数据是否存在
python -c "from pathlib import Path; p=Path(r'{REPO_ROOT}/爬取题目/output'); print([f.parent.name for f in p.glob('*/index.json')])"

# Task 1: 验证采样
python -c "import json; print(len(json.load(open(r'{REPO_ROOT}/finiteness_verification/data/sample_pilot.json',encoding='utf-8'))))"
python -c "import json; print(len(json.load(open(r'{REPO_ROOT}/finiteness_verification/data/sample_phase1.json',encoding='utf-8'))))"

# Task 3: Pilot 验证
python -c "import os; print(len(os.listdir(r'{REPO_ROOT}/finiteness_verification/output/pilot/voted/')))"

# Task 4: 饱和曲线
python -c "import json; print(json.load(open(r'{REPO_ROOT}/finiteness_verification/output/phase1/saturation_curves/metrics.json',encoding='utf-8')))"

# Task 5: 覆盖率
python -c "import json; print(json.load(open(r'{REPO_ROOT}/finiteness_verification/output/phase2/coverage_report.json',encoding='utf-8')))"
```

### Final Checklist
- [ ] 四维 I/C/O/V 均完成开放探索 + 受控验证
- [ ] 形成“有限可列”量化判断与结论
- [ ] 输出可复现的统计与证据文件
