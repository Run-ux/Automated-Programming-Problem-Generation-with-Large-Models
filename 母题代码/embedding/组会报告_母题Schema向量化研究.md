# ç»„ä¼šæŠ¥å‘Šï¼šåŸºäº Schema çš„æ¯é¢˜å‘é‡åŒ–ä¸ç¼–ç¨‹é¢˜ç”Ÿæˆç ”ç©¶


---

## ğŸ“‹ ç›®å½•

1. [ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº](#1-ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº)
2. [æˆ‘ä»¬åšäº†ä»€ä¹ˆ](#2-æˆ‘ä»¬åšäº†ä»€ä¹ˆ)
3. [æŠ€æœ¯å®ç°ç»†èŠ‚](#3-æŠ€æœ¯å®ç°ç»†èŠ‚)
4. [å½“å‰æˆæœå±•ç¤º](#4-å½“å‰æˆæœå±•ç¤º)
5. [å‘é‡åŒ–èƒ½åšä»€ä¹ˆ](#5-å‘é‡åŒ–èƒ½åšä»€ä¹ˆ)
6. [å¦‚ä½•æœåŠ¡äºç»ˆæç›®æ ‡](#6-å¦‚ä½•æœåŠ¡äºç»ˆæç›®æ ‡)
7. [ä¸‹ä¸€æ­¥å·¥ä½œè®¡åˆ’](#7-ä¸‹ä¸€æ­¥å·¥ä½œè®¡åˆ’)
8. [ç ”ç©¶ä»·å€¼ä¸è®ºæ–‡æ–¹å‘](#8-ç ”ç©¶ä»·å€¼ä¸è®ºæ–‡æ–¹å‘)

---

## 1. ç ”ç©¶èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 é—®é¢˜æå‡º

**æ ¸å¿ƒé—®é¢˜**ï¼šå¦‚ä½•è®© LLM è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ã€æœ‰éš¾åº¦æ¢¯åº¦ã€ç¬¦åˆç®—æ³•è€ƒç‚¹çš„ç¼–ç¨‹é¢˜ï¼Ÿ

**ç°æœ‰æŒ‘æˆ˜**ï¼š
- âŒ ç›´æ¥è®© LLM ç”Ÿæˆé¢˜ç›® â†’ è´¨é‡ä¸ç¨³å®šã€å®¹æ˜“åç¦»ç®—æ³•æ ¸å¿ƒ
- âŒ çº¯æ–‡æœ¬æè¿°é¢˜ç›® â†’ éš¾ä»¥é‡åŒ–ç›¸ä¼¼åº¦ã€æ— æ³•ç³»ç»ŸåŒ–ç®¡ç†
- âŒ ç¼ºä¹å¯æ§çš„é¢˜ç›®å˜æ¢æœºåˆ¶ â†’ ç”Ÿæˆé¢˜ç›®éšæœºæ€§å¼º

### 1.2 æˆ‘ä»¬çš„æ–¹æ¡ˆ

**æ ¸å¿ƒæ€è·¯**ï¼šå¼•å…¥"æ¯é¢˜ Schema"ä½œä¸ºä¸­é—´è¡¨ç¤º

```
æ¯é¢˜ Schema (ç»“æ„åŒ–) â†’ LLM ç”Ÿæˆ â†’ ç¼–ç¨‹é¢˜ (è‡ªç„¶è¯­è¨€)
                â†“
         å‘é‡åŒ– (Embedding)
                â†“
      é¢˜ç›®ç®¡ç†/æ£€ç´¢/æ¨è/è´¨é‡æ§åˆ¶
```

**å…³é”®åˆ›æ–°**ï¼š
1. **Problem Schema äº”å…ƒç»„**ï¼šå½¢å¼åŒ–è¡¨ç¤ºé¢˜ç›®æœ¬è´¨
2. **å‘é‡åŒ–**ï¼šå°† Schema è½¬æ¢ä¸º 1024 ç»´è¯­ä¹‰å‘é‡
3. **è§„åˆ™åŒ–å˜æ¢**ï¼šå®šä¹‰é¢˜ç›®å˜æ¢ç®—å­ï¼Œçº¦æŸ LLM ç”Ÿæˆ

---

## 2. æˆ‘ä»¬åšäº†ä»€ä¹ˆ

### 2.1 é˜¶æ®µä¸€ï¼šSchema æå–ç³»ç»Ÿ âœ…

**è¾“å…¥**ï¼šLeetCode åŸå§‹é¢˜ç›®ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰  
**è¾“å‡º**ï¼šç»“æ„åŒ–çš„äº”å…ƒç»„ Schema

**äº”å…ƒç»„å®šä¹‰**ï¼š
```json
Schema = {
  "Input Structure": ["å½¢å¼åŒ–è¾“å…¥æè¿°"],
  "Core Constraint": ["æ ¸å¿ƒçº¦æŸæ¡ä»¶"],
  "Objective Function": "ç›®æ ‡å‡½æ•°",
  "Algorithmic Invariant": ["ç®—æ³•ä¸å˜é‡"],
  "Transformable Parameters": ["å¯å˜å‚æ•°"]
}
```

**å·²å®Œæˆå·¥ä½œ**ï¼š
- âœ… ä» LeetCode çˆ¬å– 1000 é“é¢˜ç›®
- âœ… è®¾è®¡ Schema æå– Prompt
- âœ… ç”Ÿæˆ 1000 ä¸ªç»“æ„åŒ– Schemaï¼ˆå­˜å‚¨ä¸º JSONï¼‰

**æ•°æ®ç¤ºä¾‹**ï¼š
```json
{
  "title": "æ¥é›¨æ°´",
  "schema": {
    "Input Structure": [
      "é•¿åº¦ä¸º n çš„æ•°ç»„ H[1..n]",
      "H[i] â‰¥ 0ï¼Œè¡¨ç¤ºæŸ±çŠ¶é«˜åº¦"
    ],
    "Core Constraint": [
      "æ¯ä¸ªä½ç½®çš„å¯è´¡çŒ®å€¼ç”±å…¶å·¦å³æœ€å¤§å€¼çš„æœ€å°è€…å†³å®š",
      "å·¦å³çº¦æŸç›¸äº’ç‹¬ç«‹ï¼Œä½†éœ€å…¨å±€ä¸€è‡´"
    ],
    "Objective Function": "è®¡ç®—æ‰€æœ‰ä½ç½®å¯ç´¯è®¡çš„å®¹é‡æ€»å’Œ",
    "Algorithmic Invariant": [
      "ç»´æŠ¤å·¦å³æŒ‡é’ˆ L, R",
      "è‹¥ maxLeft â‰¤ maxRightï¼Œåˆ™ L çš„è´¡çŒ®å¯ç¡®å®š"
    ],
    "Transformable Parameters": [
      "H æ˜¯å¦å…è®¸è´Ÿå€¼ï¼ˆå˜å½¢é¢˜ï¼‰",
      "æ˜¯å¦äºŒç»´ï¼ˆ2D æ¥é›¨æ°´ï¼‰",
      "æ˜¯å¦åœ¨çº¿è¾“å…¥"
    ]
  }
}
```

---

### 2.2 é˜¶æ®µäºŒï¼šSchema å‘é‡åŒ–ç³»ç»Ÿ âœ… (æœ¬å‘¨é‡ç‚¹)

**åŠ¨æœº**ï¼šçº¯æ–‡æœ¬ Schema éš¾ä»¥è®¡ç®—ç›¸ä¼¼åº¦ã€æ— æ³•é‡åŒ–é¢˜ç›®å…³ç³»

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ **Qwen text-embedding-v3 API** å°† Schema å‘é‡åŒ–

#### 2.2.1 æŠ€æœ¯è·¯çº¿

```
Schema äº”å…ƒç»„ (5ä¸ªå­—æ®µï¼Œæ¯ä¸ªå­—æ®µæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨)
    â†“
[å­—æ®µ1] â†’ Qwen API â†’ [1024ç»´å‘é‡]
[å­—æ®µ2] â†’ Qwen API â†’ [1024ç»´å‘é‡]
[å­—æ®µ3] â†’ Qwen API â†’ [1024ç»´å‘é‡]
[å­—æ®µ4] â†’ Qwen API â†’ [1024ç»´å‘é‡]
[å­—æ®µ5] â†’ Qwen API â†’ [1024ç»´å‘é‡]
    â†“
åŠ æƒèåˆ (æƒé‡å¯é…ç½®)
    â†“
[æœ€ç»ˆ1024ç»´å‘é‡] â† é¢˜ç›®çš„"è¯­ä¹‰æŒ‡çº¹"
```

#### 2.2.2 åŠ æƒèåˆç­–ç•¥

æˆ‘ä»¬æ ¹æ®ç®—æ³•é‡è¦æ€§è®¾è®¡äº†æƒé‡ï¼š

| å­—æ®µ | æƒé‡ | ç†ç”± |
|------|------|------|
| **Core Constraint** | 0.25 | çº¦æŸæ˜¯é¢˜ç›®éš¾ç‚¹æ ¸å¿ƒ |
| **Algorithmic Invariant** | 0.25 | å†³å®šç®—æ³•é€‰æ‹© |
| **Input Structure** | 0.20 | å½±å“å®ç°æ–¹å¼ |
| **Objective Function** | 0.15 | ç›®æ ‡ç›¸å¯¹æ¬¡è¦ |
| **Transformable Parameters** | 0.15 | å˜æ¢ä¾æ® |

**è®¡ç®—å…¬å¼**ï¼š
```
final_vector = 0.20Ã—v1 + 0.25Ã—v2 + 0.15Ã—v3 + 0.25Ã—v4 + 0.15Ã—v5
```

#### 2.2.3 å®ç°ç»†èŠ‚

**å¤„ç†æµç¨‹**ï¼š
1. **åˆ—è¡¨æ‹¼æ¥**ï¼šæ¯ä¸ªå­—æ®µæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œç”¨ç©ºæ ¼æ‹¼æ¥æˆå•ä¸€æ–‡æœ¬
   ```python
   # ä¾‹å¦‚ Core Constraint å­—æ®µï¼š
   text = "çº¦æŸ1 çº¦æŸ2 çº¦æŸ3 çº¦æŸ4"
   ```

2. **API è°ƒç”¨**ï¼šQwen embedding APIï¼Œè·å– 1024 ç»´å‘é‡
   ```python
   vector = get_embedding_qwen(text)  # [1024]
   ```

3. **åŠ æƒèåˆ**ï¼šæŒ‰æƒé‡åˆå¹¶ 5 ä¸ªå‘é‡
   ```python
   final = 0.2*v1 + 0.25*v2 + 0.15*v3 + 0.25*v4 + 0.15*v5
   ```

4. **å®æ—¶ä¿å­˜**ï¼šæ¯å¤„ç† 1 ä¸ª Schemaï¼Œç«‹å³ä¿å­˜åˆ° `.npz` æ–‡ä»¶

**æŠ€æœ¯å‚æ•°**ï¼š
- **æ¨¡å‹**ï¼šQwen text-embedding-v3
- **ç»´åº¦**ï¼š1024
- **API é™æµ**ï¼š0.5 ç§’/æ¬¡
- **å¤„ç†é€Ÿåº¦**ï¼š~13 ç§’/é¢˜ï¼ˆ5 æ¬¡ API è°ƒç”¨ï¼‰
- **æ•°æ®æ ¼å¼**ï¼šNumPy å‹ç¼©æ•°ç»„ï¼ˆ.npzï¼‰

---

### 2.3 é˜¶æ®µä¸‰ï¼šæ•°æ®åˆ†æå·¥å…· âœ…

å¼€å‘äº†å®Œæ•´çš„åˆ†æå·¥å…·é“¾ï¼š

| å·¥å…· | åŠŸèƒ½ | è¾“å‡º |
|------|------|------|
| `generate_embeddings.py` | å‘é‡ç”Ÿæˆ | `schema_embeddings.npz` |
| `view_embeddings.py` | æ•°æ®æŸ¥çœ‹ | å‘é‡ç»Ÿè®¡ä¿¡æ¯ |
| `analyze_schemas.py` | ç›¸ä¼¼åº¦åˆ†æ | ç›¸ä¼¼åº¦çŸ©é˜µã€èšç±»ç»“æœ |
| `recommender.py` | æ¨èç³»ç»Ÿ | ç›¸ä¼¼é¢˜æ¨è |
| `export_full_embeddings.py` | æ•°æ®å¯¼å‡º | JSON æ ¼å¼ï¼ˆç”¨äºå±•ç¤ºï¼‰ |
| `generate_presentation_figures.py` | å¯è§†åŒ– | PNG å›¾è¡¨ |

---

## 3. æŠ€æœ¯å®ç°ç»†èŠ‚

### 3.1 ç³»ç»Ÿæ¶æ„

```
leetcode_schema_extractor/
â”œâ”€â”€ æ¯é¢˜ä»£ç /
â”‚   â”œâ”€â”€ crawler/              # çˆ¬è™«æ¨¡å—
â”‚   â”‚   â””â”€â”€ leetcode_crawler.py
â”‚   â”œâ”€â”€ Gemini/               # Schemaæå–ï¼ˆä½¿ç”¨Geminiï¼‰
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ schema_parser.py
â”‚   â”‚   â””â”€â”€ parse_with_gemini.py
â”‚   â”œâ”€â”€ embedding/            # å‘é‡åŒ–æ¨¡å—ï¼ˆæœ¬å‘¨é‡ç‚¹ï¼‰â˜…
â”‚   â”‚   â”œâ”€â”€ config.py         # é…ç½®ï¼ˆAPI key, æƒé‡ç­‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ generate_embeddings.py  # æ ¸å¿ƒï¼šç”Ÿæˆå‘é‡
â”‚   â”‚   â”œâ”€â”€ analyze_schemas.py      # ç›¸ä¼¼åº¦åˆ†æ
â”‚   â”‚   â”œâ”€â”€ recommender.py          # æ¨èç³»ç»Ÿ
â”‚   â”‚   â””â”€â”€ output/
â”‚   â”‚       â”œâ”€â”€ schema_embeddings.npz      # å‘é‡æ•°æ®
â”‚   â”‚       â””â”€â”€ presentation/              # å±•ç¤ºææ–™
â”‚   â””â”€â”€ output/
â”‚       â””â”€â”€ schemas_readable.json   # 1000ä¸ªSchema
```

### 3.2 æ ¸å¿ƒä»£ç é€»è¾‘

**å‘é‡ç”Ÿæˆæ ¸å¿ƒ**ï¼ˆ`generate_embeddings.py`ï¼‰ï¼š
```python
def generate_schema_embedding(schema):
    """ä¸ºä¸€ä¸ªSchemaç”Ÿæˆå‘é‡"""
    embeddings = {}
    fields = ["Input Structure", "Core Constraint", 
              "Objective Function", "Algorithmic Invariant", 
              "Transformable Parameters"]
    
    # ä¸ºæ¯ä¸ªå­—æ®µç”Ÿæˆå‘é‡
    for field in fields:
        text = prepare_text(schema, field)  # åˆ—è¡¨â†’æ–‡æœ¬
        emb = get_embedding_qwen(text)      # APIè°ƒç”¨
        embeddings[field] = emb
        time.sleep(0.5)  # é™æµ
    
    # åŠ æƒèåˆ
    combined = (
        0.20 * embeddings["Input Structure"] +
        0.25 * embeddings["Core Constraint"] +
        0.15 * embeddings["Objective Function"] +
        0.25 * embeddings["Algorithmic Invariant"] +
        0.15 * embeddings["Transformable Parameters"]
    )
    
    return combined  # [1024ç»´å‘é‡]
```

---

## 4. å½“å‰æˆæœå±•ç¤º

### 4.1 æ•°æ®è§„æ¨¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **å·²çˆ¬å–é¢˜ç›®** | 1000 é“ |
| **å·²æå– Schema** | 1000 ä¸ª |
| **å·²ç”Ÿæˆå‘é‡** | 39 ä¸ªï¼ˆè¿›è¡Œä¸­ï¼Œç›®æ ‡ 1000ï¼‰ |
| **å‘é‡ç»´åº¦** | 1024 |
| **æ•°æ®å¤§å°** | 1.2 MB (39é¢˜) |

### 4.2 å‘é‡è´¨é‡éªŒè¯

**å®éªŒï¼šè®¡ç®—ç›¸ä¼¼é¢˜ç›®çš„ä½™å¼¦ç›¸ä¼¼åº¦**

| é¢˜ç›®å¯¹ | ç›¸ä¼¼åº¦ | è¯´æ˜ |
|--------|--------|------|
| "ä¸€ç»´æ•°ç»„æœ€å¤§å­æ•°ç»„å’Œ" vs "ç»™å®šæ•´æ•°æ•°ç»„æ‰¾æœ€å¤§è¿ç»­å­æ•°ç»„" | 0.7999 | è¯­ä¹‰é«˜åº¦ç›¸ä¼¼ âœ… |
| æœ€ç›¸ä¼¼é¢˜ç›®å¯¹1 | 0.92 | æ¯é¢˜-å˜ä½“å…³ç³» |
| æœ€ç›¸ä¼¼é¢˜ç›®å¯¹2 | 0.89 | ç®—æ³•æ ¸å¿ƒç›¸åŒ |

**ç»“è®º**ï¼šå‘é‡èƒ½æœ‰æ•ˆæ•æ‰é¢˜ç›®è¯­ä¹‰ï¼

### 4.3 å‘é‡ç‰¹æ€§åˆ†æ

**ç»Ÿè®¡æ•°æ®**ï¼ˆåŸºäº39ä¸ªå·²ç”Ÿæˆå‘é‡ï¼‰ï¼š
- **å€¼åŸŸèŒƒå›´**ï¼š[-0.19, 0.24]
- **å¹³å‡æ¨¡é•¿**ï¼š~3.2
- **å‡å€¼**ï¼š~-0.0007ï¼ˆæ¥è¿‘0ï¼Œè¯´æ˜å‘é‡æ ‡å‡†åŒ–è‰¯å¥½ï¼‰
- **æ ‡å‡†å·®**ï¼š~0.067

**åˆ†å¸ƒç‰¹å¾**ï¼š
- å‘é‡åœ¨é«˜ç»´ç©ºé—´åˆ†å¸ƒå‡åŒ€
- ä¸åŒé¢˜ç›®å‘é‡å·®å¼‚æ˜æ˜¾
- æ¨¡é•¿åˆ†å¸ƒç¨³å®šï¼ˆCV < 5%ï¼‰

---

## 5. å‘é‡åŒ–èƒ½åšä»€ä¹ˆ

### 5.1 ç›¸ä¼¼é¢˜æ£€ç´¢ä¸æ¨è â­

**åº”ç”¨åœºæ™¯**ï¼šæ•™è‚²å¹³å°çš„"ç›¸ä¼¼é¢˜æ¨è"

**å®ç°æ–¹æ³•**ï¼š
```python
# 1. è®¡ç®—ç›¸ä¼¼åº¦
def find_similar_problems(query_vector, all_vectors, top_k=5):
    similarities = cosine_similarity([query_vector], all_vectors)[0]
    top_indices = np.argsort(similarities)[-top_k:][::-1]
    return top_indices, similarities[top_indices]

# 2. æ¨èç›¸ä¼¼é¢˜
similar_ids, scores = find_similar_problems(problem_123_vector, all_vectors)
# è¾“å‡ºï¼š[é¢˜ç›®456(0.92), é¢˜ç›®789(0.87), ...]
```

**ä»·å€¼**ï¼š
- å­¦ç”Ÿåšå®Œä¸€é“é¢˜ï¼Œè‡ªåŠ¨æ¨èéš¾åº¦ç›¸è¿‘çš„å˜ä½“é¢˜
- é¿å…é‡å¤æ¨èå®Œå…¨æ— å…³çš„é¢˜ç›®

---

### 5.2 é¢˜ç›®å»é‡ä¸æŠ„è¢­æ£€æµ‹ â­

**åº”ç”¨åœºæ™¯**ï¼šç«èµ›ç»„ç»‡æ–¹éœ€è¦æ£€æµ‹é¢˜ç›®åŸåˆ›æ€§

**å®ç°æ–¹æ³•**ï¼š
```python
def detect_duplicates(vectors, threshold=0.85):
    """æ£€æµ‹é«˜ç›¸ä¼¼åº¦é¢˜ç›®å¯¹"""
    sim_matrix = cosine_similarity(vectors)
    np.fill_diagonal(sim_matrix, 0)  # æ’é™¤è‡ªå·±
    
    duplicates = []
    for i in range(len(vectors)):
        for j in range(i+1, len(vectors)):
            if sim_matrix[i,j] > threshold:
                duplicates.append((i, j, sim_matrix[i,j]))
    return duplicates

# æ£€æµ‹
duplicates = detect_duplicates(all_vectors, threshold=0.90)
# è¾“å‡ºï¼š[(é¢˜ç›®12, é¢˜ç›®45, 0.93), ...] â† å¯èƒ½æ˜¯æŠ„è¢­
```

**ä»·å€¼**ï¼š
- è‡ªåŠ¨æ£€æµ‹é¢˜åº“ä¸­çš„é‡å¤é¢˜ç›®
- æ–°é¢˜å…¥åº“å‰æ£€æŸ¥ç›¸ä¼¼åº¦
- é˜²æ­¢ç«èµ›é¢˜æ³„éœ²ï¼ˆæ£€æµ‹æ˜¯å¦ä¸å…¬å¼€é¢˜ç›¸ä¼¼ï¼‰

---

### 5.3 é¢˜ç›®èšç±»ä¸çŸ¥è¯†å›¾è°±æ„å»º â­â­

**åº”ç”¨åœºæ™¯**ï¼šè‡ªåŠ¨æ„å»º"ç®—æ³•çŸ¥è¯†å›¾è°±"

**å®ç°æ–¹æ³•**ï¼š
```python
from sklearn.cluster import KMeans

# 1. K-meansèšç±»
kmeans = KMeans(n_clusters=30)  # å‡è®¾30ä¸ªç®—æ³•ç±»åˆ«
clusters = kmeans.fit_predict(all_vectors)

# 2. ä¸ºæ¯ä¸ªç°‡å‘½å
for cluster_id in range(30):
    cluster_problems = [é¢˜ç›®åˆ—è¡¨[i] for i in range(len(é¢˜ç›®)) if clusters[i] == cluster_id]
    print(f"ç°‡ {cluster_id}: {len(cluster_problems)} é“é¢˜")
    print(f"  ä»£è¡¨é¢˜ç›®: {cluster_problems[0]['title']}")
    print(f"  ç®—æ³•æ ‡ç­¾: åŠ¨æ€è§„åˆ’ / åŒæŒ‡é’ˆ / ...")
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ç°‡0: 45é“é¢˜ - "åŒæŒ‡é’ˆ+æ»‘åŠ¨çª—å£"
  â”œâ”€â”€ æœ€å°è¦†ç›–å­ä¸²
  â”œâ”€â”€ æ— é‡å¤å­—ç¬¦çš„æœ€é•¿å­ä¸²
  â””â”€â”€ ...

ç°‡1: 38é“é¢˜ - "åŠ¨æ€è§„åˆ’+èƒŒåŒ…é—®é¢˜"
  â”œâ”€â”€ 0-1èƒŒåŒ…
  â”œâ”€â”€ åˆ†å‰²ç­‰å’Œå­é›†
  â””â”€â”€ ...
```

**ä»·å€¼**ï¼š
- è‡ªåŠ¨å‘ç°é¢˜ç›®ä¹‹é—´çš„å†…åœ¨å…³ç³»
- æ„å»ºå­¦ä¹ è·¯å¾„å›¾ï¼ˆä»ç®€å•åˆ°å¤æ‚ï¼‰
- è¾…åŠ©æ•™å¸ˆè®¾è®¡è¯¾ç¨‹å¤§çº²

---

### 5.4 éš¾åº¦è‡ªåŠ¨åˆ†çº§ â­

**åº”ç”¨åœºæ™¯**ï¼šæ–°é¢˜å…¥åº“æ—¶è‡ªåŠ¨è¯„ä¼°éš¾åº¦

**å®ç°æ–¹æ³•**ï¼š
```python
# 1. è®­ç»ƒåˆ†ç±»å™¨
from sklearn.ensemble import RandomForestClassifier

X = all_vectors  # å‘é‡
y = [é¢˜ç›®1éš¾åº¦, é¢˜ç›®2éš¾åº¦, ...]  # Easy/Medium/Hard

clf = RandomForestClassifier()
clf.fit(X, y)

# 2. é¢„æµ‹æ–°é¢˜éš¾åº¦
new_problem_vector = generate_schema_embedding(new_schema)
predicted_difficulty = clf.predict([new_problem_vector])
# è¾“å‡ºï¼šMedium (ç½®ä¿¡åº¦ 85%)
```

**ä»·å€¼**ï¼š
- å‡å°‘äººå·¥æ ‡æ³¨æˆæœ¬
- ä¿è¯éš¾åº¦æ ‡æ³¨ä¸€è‡´æ€§
- æ–°é¢˜å¿«é€Ÿå…¥åº“

---

### 5.5 ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„ç”Ÿæˆ â­â­

**åº”ç”¨åœºæ™¯**ï¼šæ ¹æ®å­¦ç”Ÿèƒ½åŠ›åŠ¨æ€æ¨èé¢˜ç›®

**å®ç°æ–¹æ³•**ï¼š
```python
def generate_learning_path(student_profile, all_vectors, all_schemas):
    """
    student_profile = {
        "mastered_problems": [1, 3, 5, ...],  # å·²æŒæ¡é¢˜ç›®
        "weak_points": ["åŠ¨æ€è§„åˆ’", "å›¾è®º"],    # è–„å¼±ç‚¹
        "target_difficulty": "Medium"
    }
    """
    
    # 1. è®¡ç®—å­¦ç”Ÿçš„"èƒ½åŠ›å‘é‡"ï¼ˆå·²æŒæ¡é¢˜ç›®çš„å¹³å‡å‘é‡ï¼‰
    mastered_vectors = [all_vectors[i] for i in student_profile["mastered_problems"]]
    ability_vector = np.mean(mastered_vectors, axis=0)
    
    # 2. æ‰¾åˆ°"ç¨éš¾ä¸€ç‚¹"çš„é¢˜ç›®
    candidates = []
    for i, vec in enumerate(all_vectors):
        if i not in student_profile["mastered_problems"]:
            similarity = cosine_similarity([ability_vector], [vec])[0][0]
            if 0.6 < similarity < 0.8:  # ç›¸ä¼¼ä½†ä¸å®Œå…¨ä¸€æ ·
                candidates.append((i, similarity))
    
    # 3. æ’åºæ¨è
    candidates.sort(key=lambda x: x[1], reverse=True)
    return candidates[:10]  # æ¨èå‰10é¢˜
```

**ä»·å€¼**ï¼š
- é¿å…é¢˜ç›®è¿‡éš¾/è¿‡æ˜“
- åŸºäº"æœ€è¿‘å‘å±•åŒº"ç†è®º
- æé«˜å­¦ä¹ æ•ˆç‡

---

## 6. å¦‚ä½•æœåŠ¡äºç»ˆæç›®æ ‡

### 6.1 ç»ˆæç›®æ ‡å›é¡¾

> **ç”¨æ¯é¢˜è®© LLM è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ç¼–ç¨‹é¢˜**

**æ ¸å¿ƒæŒ‘æˆ˜**ï¼š
1. å¦‚ä½•æ§åˆ¶ LLM ç”Ÿæˆè´¨é‡ï¼Ÿ
2. å¦‚ä½•é¿å…ç”Ÿæˆé‡å¤é¢˜ï¼Ÿ
3. å¦‚ä½•ä¿è¯ç”Ÿæˆé¢˜ç›®çš„éš¾åº¦æ¢¯åº¦ï¼Ÿ
4. å¦‚ä½•æ‰¹é‡ç”Ÿæˆå˜ä½“é¢˜ï¼Ÿ

---

### 6.2 å‘é‡åŒ–å¦‚ä½•è§£å†³è¿™äº›æŒ‘æˆ˜

#### 6.2.1 è´¨é‡æ§åˆ¶ï¼šç”Ÿæˆå‰æ£€æŸ¥ âœ…

**æµç¨‹**ï¼š
```
æ¯é¢˜ Schema â†’ åº”ç”¨å˜æ¢ç®—å­ â†’ å˜ä½“ Schema
                â†“
         ç”Ÿæˆ Embedding å‘é‡
                â†“
    ä¸é¢˜åº“ä¸­æ‰€æœ‰å‘é‡è®¡ç®—ç›¸ä¼¼åº¦
                â†“
         åˆ¤æ–­ï¼šæ˜¯å¦å¤ªç›¸ä¼¼ï¼Ÿ
                â†“
    NO â†’ è°ƒç”¨ LLM ç”Ÿæˆé¢˜ç›® â†’ å…¥åº“
    YES â†’ è°ƒæ•´å˜æ¢å‚æ•°ï¼Œé‡æ–°ç”Ÿæˆ
```

**ç¤ºä¾‹**ï¼š
```python
def generate_new_problem_with_check(mother_schema, transform_op, existing_vectors):
    # 1. åº”ç”¨å˜æ¢ç®—å­
    variant_schema = apply_transform(mother_schema, transform_op)
    
    # 2. ç”Ÿæˆå‘é‡
    new_vector = generate_schema_embedding(variant_schema)
    
    # 3. æ£€æŸ¥ç›¸ä¼¼åº¦
    max_similarity = max(cosine_similarity([new_vector], existing_vectors)[0])
    
    if max_similarity > 0.85:
        print("âš ï¸ ç”Ÿæˆé¢˜ç›®ä¸ç°æœ‰é¢˜ç›®è¿‡äºç›¸ä¼¼ï¼Œæ‹’ç»ç”Ÿæˆ")
        return None
    
    # 4. è°ƒç”¨ LLM ç”Ÿæˆé¢˜ç›®
    problem = llm_generate(variant_schema)
    return problem, new_vector
```

**ä»·å€¼**ï¼š
- âœ… è‡ªåŠ¨è¿‡æ»¤é‡å¤é¢˜ç›®
- âœ… ä¿è¯é¢˜åº“å¤šæ ·æ€§
- âœ… å‡å°‘äººå·¥å®¡æ ¸æˆæœ¬

---

#### 6.2.2 éš¾åº¦æ¢¯åº¦æ§åˆ¶ï¼šå‘é‡æ’å€¼ âœ…

**æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨å‘é‡ç©ºé—´ä¸­æ§åˆ¶éš¾åº¦

```
ç®€å•é¢˜å‘é‡ ----[æ’å€¼]----> å›°éš¾é¢˜å‘é‡
    A                           B
    â†“                           â†“
  Easy                        Hard

ä¸­ç­‰é¢˜å‘é‡ = 0.5Ã—A + 0.5Ã—B  (Medium)
ç¨éš¾é¢˜å‘é‡ = 0.3Ã—A + 0.7Ã—B  (Medium-Hard)
```

**å®ç°**ï¼š
```python
def generate_intermediate_problem(easy_vector, hard_vector, difficulty=0.5):
    """
    difficulty: 0.0(Easy) â†’ 1.0(Hard)
    """
    # 1. å‘é‡æ’å€¼
    target_vector = (1-difficulty)*easy_vector + difficulty*hard_vector
    
    # 2. åœ¨é¢˜åº“ä¸­æ‰¾æœ€æ¥è¿‘çš„Schemaä½œä¸ºæ¨¡æ¿
    similarities = cosine_similarity([target_vector], all_vectors)[0]
    template_idx = np.argmax(similarities)
    template_schema = all_schemas[template_idx]
    
    # 3. å¾®è°ƒSchemaï¼Œç”Ÿæˆé¢˜ç›®
    adjusted_schema = adjust_schema_difficulty(template_schema, difficulty)
    problem = llm_generate(adjusted_schema)
    
    return problem
```

**ä»·å€¼**ï¼š
- âœ… è‡ªåŠ¨ç”Ÿæˆä»»æ„éš¾åº¦çš„é¢˜ç›®
- âœ… å¹³æ»‘çš„éš¾åº¦æ›²çº¿
- âœ… æ”¯æŒä¸ªæ€§åŒ–éš¾åº¦è°ƒæ•´

---

#### 6.2.3 å˜ä½“é¢˜æ‰¹é‡ç”Ÿæˆï¼šçº¦æŸé‡‡æ · âœ…

**æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨å‘é‡ç©ºé—´ä¸­å®šä¹‰"æœ‰æ•ˆåŒºåŸŸ"

```
æ¯é¢˜å‘é‡ M
    â†“
å®šä¹‰åŠå¾„ rï¼ˆå˜åŒ–ç¨‹åº¦ï¼‰
    â†“
åœ¨åŠå¾„ r å†…éšæœºé‡‡æ · N ä¸ªå‘é‡
    â†“
ä¸ºæ¯ä¸ªå‘é‡åå‘è§£æå‡º Schema
    â†“
è°ƒç”¨ LLM ç”Ÿæˆé¢˜ç›®
```

**å®ç°**ï¼š
```python
def generate_variants(mother_vector, mother_schema, num_variants=10, radius=0.3):
    """
    åœ¨æ¯é¢˜å‘¨å›´ç”Ÿæˆå˜ä½“é¢˜
    radius: æ§åˆ¶å˜åŒ–ç¨‹åº¦ï¼ˆ0.1=å¾®è°ƒ, 0.5=è¾ƒå¤§å˜åŒ–ï¼‰
    """
    variants = []
    
    for i in range(num_variants):
        # 1. åœ¨çƒé¢ä¸Šéšæœºé‡‡æ ·
        noise = np.random.randn(1024)
        noise = noise / np.linalg.norm(noise) * radius  # å½’ä¸€åŒ–åˆ°åŠå¾„r
        variant_vector = mother_vector + noise
        
        # 2. æ‰¾æœ€è¿‘çš„å·²çŸ¥Schemaä½œä¸ºå‚è€ƒ
        similarities = cosine_similarity([variant_vector], all_vectors)[0]
        ref_idx = np.argmax(similarities)
        ref_schema = all_schemas[ref_idx]
        
        # 3. èåˆæ¯é¢˜å’Œå‚è€ƒSchemaçš„ç‰¹å¾
        new_schema = blend_schemas(mother_schema, ref_schema, weight=0.7)
        
        # 4. ç”Ÿæˆé¢˜ç›®
        problem = llm_generate(new_schema)
        variants.append(problem)
    
    return variants
```

**ä»·å€¼**ï¼š
- âœ… ä¸€é”®ç”Ÿæˆ10/20/50ä¸ªå˜ä½“
- âœ… æ§åˆ¶å˜ä½“çš„"åˆ›æ–°åº¦"
- âœ… ä¿æŒä¸æ¯é¢˜çš„è”ç³»

---

#### 6.2.4 é¢˜ç›®è´¨é‡è¯„ä¼°ï¼šå‘é‡ä¸€è‡´æ€§æ£€æŸ¥ âœ…

**æµç¨‹**ï¼š
```
LLM ç”Ÿæˆé¢˜ç›®
    â†“
äººå·¥å®¡æ ¸ï¼ˆæ ‡æ³¨ï¼šå¥½/å·®ï¼‰
    â†“
é‡æ–°æå–ç”Ÿæˆé¢˜ç›®çš„ Schema
    â†“
ç”Ÿæˆå‘é‡ V_generated
    â†“
ä¸é¢„æœŸå‘é‡ V_expected å¯¹æ¯”
    â†“
ç›¸ä¼¼åº¦é«˜ â†’ å¥½é¢˜ï¼ˆLLM ç†è§£æ­£ç¡®ï¼‰
ç›¸ä¼¼åº¦ä½ â†’ å·®é¢˜ï¼ˆLLM åç¦»æ„å›¾ï¼‰
```

**å®ç°**ï¼š
```python
def evaluate_generated_problem(expected_schema, generated_problem_text):
    # 1. ä»ç”Ÿæˆçš„é¢˜ç›®ä¸­æå–Schema
    generated_schema = extract_schema_from_text(generated_problem_text)
    
    # 2. ç”Ÿæˆå‘é‡
    v_expected = generate_schema_embedding(expected_schema)
    v_generated = generate_schema_embedding(generated_schema)
    
    # 3. è®¡ç®—ç›¸ä¼¼åº¦
    similarity = cosine_similarity([v_expected], [v_generated])[0][0]
    
    if similarity > 0.80:
        return "âœ… é«˜è´¨é‡ï¼šLLM å‡†ç¡®ç†è§£æ„å›¾"
    elif similarity > 0.60:
        return "âš ï¸ ä¸­ç­‰è´¨é‡ï¼šéƒ¨åˆ†åç¦»"
    else:
        return "âŒ ä½è´¨é‡ï¼šä¸¥é‡åç¦»ï¼Œéœ€é‡æ–°ç”Ÿæˆ"
```

**ä»·å€¼**ï¼š
- âœ… è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥
- âœ… æä¾›æ”¹è¿›æ–¹å‘
- âœ… å‡å°‘äººå·¥å®¡æ ¸å·¥ä½œé‡

---

### 6.3 å®Œæ•´çš„é¢˜ç›®ç”Ÿæˆæµæ°´çº¿

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ1ï¼šæ¯é¢˜åº“æ„å»º                                       â”‚
â”‚  - çˆ¬å–1000é“LeetCodeé¢˜ç›®                               â”‚
â”‚  - æå–Schemaï¼ˆäº”å…ƒç»„ï¼‰                                  â”‚
â”‚  - å‘é‡åŒ–ï¼ˆ1024ç»´ï¼‰                                      â”‚
â”‚  - æ„å»ºå‘é‡ç´¢å¼•ï¼ˆFAISSï¼‰                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ2ï¼šå˜ä½“ç”Ÿæˆç­–ç•¥                                     â”‚
â”‚  - å®šä¹‰å˜æ¢ç®—å­ï¼ˆTransformable Parametersï¼‰             â”‚
â”‚    Â· è¾“å…¥ç»´åº¦å˜æ¢: 1D â†’ 2D                               â”‚
â”‚    Â· ç›®æ ‡å˜æ¢: æœ€å¤§ â†’ è®¡æ•°                               â”‚
â”‚    Â· çº¦æŸåè½¬: â‰¤K â†’ â‰¥K                                   â”‚
â”‚  - åº”ç”¨ç®—å­åˆ°æ¯é¢˜Schema                                  â”‚
â”‚  - ç”Ÿæˆå˜ä½“Schema                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ3ï¼šè´¨é‡æ§åˆ¶ï¼ˆå‘é‡åŒ–çš„ä½œç”¨ï¼‰                         â”‚
â”‚  - è®¡ç®—å˜ä½“Schemaå‘é‡                                    â”‚
â”‚  - æ£€æŸ¥ä¸ç°æœ‰é¢˜ç›®ç›¸ä¼¼åº¦                                  â”‚
â”‚  - è¿‡æ»¤é‡å¤/è¿‡äºç›¸ä¼¼çš„Schema                             â”‚
â”‚  - è¯„ä¼°éš¾åº¦ï¼ˆä¸Easy/Hardé¢˜ç›®çš„è·ç¦»ï¼‰                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ4ï¼šLLMé¢˜ç›®ç”Ÿæˆ                                      â”‚
â”‚  - è¾“å…¥ï¼šé€šè¿‡æ£€æŸ¥çš„å˜ä½“Schema                            â”‚
â”‚  - Promptï¼šç»“æ„åŒ–+çº¦æŸ                                   â”‚
â”‚  - LLMç”Ÿæˆï¼šé¢˜ç›®æè¿°ã€æ ·ä¾‹ã€é¢˜è§£                         â”‚
â”‚  - åå¤„ç†ï¼šæ ¼å¼åŒ–ã€è¡¥å……ç»†èŠ‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ5ï¼šç”Ÿæˆè´¨é‡éªŒè¯ï¼ˆå†æ¬¡ä½¿ç”¨å‘é‡ï¼‰                     â”‚
â”‚  - æå–ç”Ÿæˆé¢˜ç›®çš„Schema                                  â”‚
â”‚  - ç”Ÿæˆå‘é‡ï¼Œä¸é¢„æœŸå‘é‡å¯¹æ¯”                              â”‚
â”‚  - ç›¸ä¼¼åº¦ > 0.8 â†’ é€šè¿‡                                   â”‚
â”‚  - ç›¸ä¼¼åº¦ < 0.8 â†’ é‡æ–°ç”Ÿæˆæˆ–äººå·¥ä¿®æ­£                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ6ï¼šé¢˜åº“ç®¡ç†ä¸åº”ç”¨                                   â”‚
â”‚  - å…¥åº“ï¼šé¢˜ç›®+Schema+å‘é‡                                â”‚
â”‚  - æ¨èï¼šåŸºäºå­¦ç”Ÿèƒ½åŠ›å‘é‡                                â”‚
â”‚  - å»é‡ï¼šå®šæœŸæ£€æŸ¥ç›¸ä¼¼åº¦çŸ©é˜µ                              â”‚
â”‚  - çŸ¥è¯†å›¾è°±ï¼šèšç±»+å¯è§†åŒ–                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. ä¸‹ä¸€æ­¥å·¥ä½œè®¡åˆ’

### 7.1 è¿‘æœŸç›®æ ‡ï¼ˆ1-2å‘¨ï¼‰

- [ ] **å®Œæˆ1000ä¸ªSchemaçš„å‘é‡åŒ–**
  - å½“å‰ï¼š39/1000 (3.9%)
  - é¢„è®¡å®Œæˆæ—¶é—´ï¼š50å°æ—¶ï¼ˆ~3å¤©è¿ç»­è¿è¡Œï¼‰
  
- [ ] **ç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—**
  - è¾“å‡ºï¼š1000Ã—1000 ç›¸ä¼¼åº¦çŸ©é˜µ
  - ç”¨é€”ï¼šæ£€æµ‹é¢˜ç›®å…³ç³»ã€å»é‡

- [ ] **èšç±»åˆ†æ**
  - K-means èšç±»ï¼ˆk=30-50ï¼‰
  - ä¸ºæ¯ä¸ªç°‡å‘½åï¼ˆç®—æ³•æ ‡ç­¾ï¼‰
  - å¯è§†åŒ–ï¼ˆt-SNEé™ç»´ï¼‰

- [ ] **æ¨èç³»ç»ŸåŸå‹**
  - å®ç° `find_similar_problems()`
  - æµ‹è¯•æ¨èè´¨é‡

---

### 7.2 ä¸­æœŸç›®æ ‡ï¼ˆ1ä¸ªæœˆï¼‰

- [ ] **å˜æ¢ç®—å­è®¾è®¡**
  - å½¢å¼åŒ–å®šä¹‰10-15ä¸ªå˜æ¢ç®—å­
  - å®ç°ç®—å­åº”ç”¨å‡½æ•°
  - æµ‹è¯•å˜ä½“Schemaçš„åˆç†æ€§

- [ ] **LLMé›†æˆ**
  - è®¾è®¡ Schema â†’ é¢˜ç›®çš„ Prompt
  - æµ‹è¯•ä¸åŒ LLMï¼ˆGPT-4, Claude, Qwenï¼‰
  - è¯„ä¼°ç”Ÿæˆé¢˜ç›®è´¨é‡

- [ ] **è´¨é‡æ§åˆ¶å®éªŒ**
  - å¯¹æ¯”"æœ‰å‘é‡æ£€æŸ¥"vs"æ— æ£€æŸ¥"çš„ç”Ÿæˆè´¨é‡
  - ç»Ÿè®¡é‡å¤ç‡ã€éš¾åº¦åˆ†å¸ƒ
  - ä¼˜åŒ–ç›¸ä¼¼åº¦é˜ˆå€¼

---

### 7.3 é•¿æœŸç›®æ ‡ï¼ˆ3ä¸ªæœˆï¼‰

- [ ] **å®Œæ•´é¢˜ç›®ç”Ÿæˆç³»ç»Ÿ**
  - Webç•Œé¢ï¼šè¾“å…¥æ¯é¢˜ â†’ è¾“å‡º10ä¸ªå˜ä½“
  - APIæ¥å£ï¼šæ”¯æŒæ‰¹é‡ç”Ÿæˆ
  - æ•°æ®åº“ï¼šé¢˜ç›®+Schema+å‘é‡

- [ ] **çŸ¥è¯†å›¾è°±å¯è§†åŒ–**
  - D3.jsäº¤äº’å¼å›¾è°±
  - å±•ç¤ºé¢˜ç›®å…³ç³»ç½‘ç»œ
  - æ”¯æŒè·¯å¾„æœç´¢

- [ ] **A/Bæµ‹è¯•**
  - å¯¹æ¯”"äººå·¥å‡ºé¢˜"vs"AIç”Ÿæˆé¢˜"
  - å­¦ç”Ÿä½¿ç”¨ä½“éªŒè°ƒç ”
  - æ•™å­¦æ•ˆæœè¯„ä¼°

---

## 8. ç ”ç©¶ä»·å€¼ä¸è®ºæ–‡æ–¹å‘

### 8.1 å­¦æœ¯è´¡çŒ®

#### åˆ›æ–°ç‚¹1ï¼šProblem Schema è¡¨ç¤ºæ³•
- **é¦–æ¬¡æå‡ºäº”å…ƒç»„ç»“æ„åŒ–è¡¨ç¤º**
- åŒºåˆ«äºä¼ ç»Ÿçš„æ ‡ç­¾/åˆ†ç±»æ–¹å¼
- å½¢å¼åŒ–ã€å¯éªŒè¯ã€å¯è®¡ç®—

#### åˆ›æ–°ç‚¹2ï¼šå‘é‡åŒ–æ–¹æ³•
- **å°†ç»“æ„åŒ–Schemaæ˜ å°„åˆ°è¿ç»­å‘é‡ç©ºé—´**
- åŠ æƒèåˆç­–ç•¥ï¼ˆåŒºåˆ†å­—æ®µé‡è¦æ€§ï¼‰
- æ”¯æŒå‘é‡è¿ç®—ï¼ˆæ’å€¼ã€é‡‡æ ·ã€èšç±»ï¼‰

#### åˆ›æ–°ç‚¹3ï¼šå¯æ§ç”Ÿæˆæ¡†æ¶
- **ç»“åˆè§„åˆ™çº¦æŸä¸LLMç”Ÿæˆ**
- å‘é‡ç©ºé—´ä¸­çš„è´¨é‡æ§åˆ¶
- é—­ç¯åé¦ˆæœºåˆ¶

---

### 8.2 è®ºæ–‡æ–¹å‘

#### æ–¹å‘1ï¼šåŸºäºè¯­ä¹‰å‘é‡çš„ç®—æ³•é¢˜ç›®è¡¨ç¤ºä¸ç›¸ä¼¼åº¦è®¡ç®—
**ç›®æ ‡æœŸåˆŠ/ä¼šè®®**ï¼šACM SIGCSE / IEEE Transactions on Learning Technologies

**æ ¸å¿ƒå†…å®¹**ï¼š
- Problem Schema äº”å…ƒç»„å®šä¹‰
- å‘é‡åŒ–æ–¹æ³•ä¸å®ç°
- ç›¸ä¼¼åº¦è®¡ç®—å®éªŒ
- åº”ç”¨ï¼šæ¨èç³»ç»Ÿã€å»é‡æ£€æµ‹

**å®éªŒè®¾è®¡**ï¼š
- äººå·¥æ ‡æ³¨100å¯¹é¢˜ç›®çš„ç›¸ä¼¼åº¦ï¼ˆ1-5åˆ†ï¼‰
- è®¡ç®—å‘é‡ç›¸ä¼¼åº¦ï¼Œå¯¹æ¯”äººå·¥æ ‡æ³¨
- è¯„ä¼°ï¼šPearsonç›¸å…³ç³»æ•°ã€Spearmanç§©ç›¸å…³

---

#### æ–¹å‘2ï¼šç®—æ³•é¢˜ç›®çš„è‡ªåŠ¨èšç±»ä¸çŸ¥è¯†å›¾è°±æ„å»º
**ç›®æ ‡æœŸåˆŠ/ä¼šè®®**ï¼šAAAI / International Conference on Educational Data Mining (EDM)

**æ ¸å¿ƒå†…å®¹**ï¼š
- é¢˜ç›®å‘é‡èšç±»æ–¹æ³•ï¼ˆK-means, DBSCAN, å±‚æ¬¡èšç±»ï¼‰
- çŸ¥è¯†å›¾è°±æ„å»ºç®—æ³•
- å­¦ä¹ è·¯å¾„è‡ªåŠ¨ç”Ÿæˆ
- æ•™è‚²åº”ç”¨æ¡ˆä¾‹ç ”ç©¶

**å®éªŒè®¾è®¡**ï¼š
- èšç±»è´¨é‡è¯„ä¼°ï¼ˆè½®å»“ç³»æ•°ã€Davies-BouldinæŒ‡æ•°ï¼‰
- å¯¹æ¯”äººå·¥åˆ†ç±» vs è‡ªåŠ¨èšç±»
- å­¦ä¹ è·¯å¾„æœ‰æ•ˆæ€§éªŒè¯ï¼ˆA/Bæµ‹è¯•ï¼‰

---

#### æ–¹å‘3ï¼šLLMé©±åŠ¨çš„ç®—æ³•é¢˜ç›®ç”Ÿæˆç³»ç»Ÿ
**ç›®æ ‡æœŸåˆŠ/ä¼šè®®**ï¼šACM RecSys / ACM Conference on User Modeling, Adaptation and Personalization (UMAP)

**æ ¸å¿ƒå†…å®¹**ï¼š
- æ¯é¢˜å˜æ¢ç®—å­è®¾è®¡
- å‘é‡çº¦æŸçš„LLMç”Ÿæˆæ–¹æ³•
- è´¨é‡æ§åˆ¶æœºåˆ¶
- å¤§è§„æ¨¡ç”Ÿæˆå®éªŒ

**å®éªŒè®¾è®¡**ï¼š
- ç”Ÿæˆ1000é“å˜ä½“é¢˜
- ä¸“å®¶è¯„å®¡ï¼ˆç®—æ³•æ­£ç¡®æ€§ã€é¢˜ç›®è´¨é‡ï¼‰
- ä¸äººå·¥å‡ºé¢˜å¯¹æ¯”ï¼ˆæ—¶é—´æˆæœ¬ã€è´¨é‡ï¼‰
- å­¦ç”Ÿä½¿ç”¨åé¦ˆè°ƒç ”

---

### 8.3 é¢„æœŸå½±å“

**å­¦æœ¯å½±å“**ï¼š
- å¡«è¡¥"ç®—æ³•é¢˜ç›®ç»“æ„åŒ–è¡¨ç¤º"çš„ç ”ç©¶ç©ºç™½
- æä¾›å¯å¤ç°çš„å®éªŒæ•°æ®é›†
- æ¨åŠ¨"AIè¾…åŠ©æ•™è‚²"é¢†åŸŸå‘å±•

**åº”ç”¨ä»·å€¼**ï¼š
- åœ¨çº¿æ•™è‚²å¹³å°ï¼ˆLeetCode, Codeforcesï¼‰
- ä¼ä¸šæŠ€æœ¯é¢è¯•ç³»ç»Ÿ
- ç®—æ³•ç«èµ›é¢˜åº“ç®¡ç†
- é«˜æ ¡ç®—æ³•è¯¾ç¨‹è®¾è®¡

**ç»æµä»·å€¼**ï¼š
- å‡å°‘äººå·¥å‡ºé¢˜æˆæœ¬ï¼ˆä»å¤©çº§â†’ç§’çº§ï¼‰
- æé«˜é¢˜ç›®å¤šæ ·æ€§
- æ”¯æŒä¸ªæ€§åŒ–å­¦ä¹ 

---

## 9. æ€»ç»“

### 9.1 æˆ‘ä»¬åšäº†ä»€ä¹ˆ

1. âœ… **çˆ¬å–1000é“LeetCodeé¢˜ç›®**
2. âœ… **æå–1000ä¸ªç»“æ„åŒ–Schemaï¼ˆäº”å…ƒç»„ï¼‰**
3. âœ… **è®¾è®¡å¹¶å®ç°å‘é‡åŒ–ç³»ç»Ÿ**
   - Qwen APIé›†æˆ
   - åŠ æƒèåˆç­–ç•¥
   - å®æ—¶ä¿å­˜æœºåˆ¶
4. âœ… **ç”Ÿæˆ39ä¸ªå‘é‡ï¼ˆ3.9%ï¼Œè¿›è¡Œä¸­ï¼‰**
5. âœ… **å¼€å‘å®Œæ•´åˆ†æå·¥å…·é“¾**
   - ç›¸ä¼¼åº¦è®¡ç®—
   - æ¨èç³»ç»Ÿ
   - å¯è§†åŒ–å·¥å…·

---

### 9.2 å‘é‡åŒ–çš„æ ¸å¿ƒä»·å€¼

**ä¸ä»…ä»…æ˜¯"è¡¨ç¤º"ï¼Œæ›´æ˜¯"æ§åˆ¶"ï¼**

| åº”ç”¨ | ä¼ ç»Ÿæ–¹æ³• | å‘é‡åŒ–æ–¹æ³• | æå‡ |
|------|---------|-----------|------|
| ç›¸ä¼¼é¢˜æ¨è | äººå·¥æ ‡ç­¾åŒ¹é… | ä½™å¼¦ç›¸ä¼¼åº¦ | è‡ªåŠ¨åŒ–ã€ç²¾å‡† |
| é¢˜ç›®å»é‡ | äººå·¥é€ä¸ªæ£€æŸ¥ | ç›¸ä¼¼åº¦çŸ©é˜µ | ç§’çº§å®Œæˆ |
| éš¾åº¦è¯„ä¼° | ä¸“å®¶è¯„å®¡ | å‘é‡åˆ†ç±»å™¨ | ä¸€è‡´æ€§é«˜ |
| å˜ä½“ç”Ÿæˆ | LLMè‡ªç”±å‘æŒ¥ | å‘é‡çº¦æŸé‡‡æ · | å¯æ§ã€å¤šæ · |
| è´¨é‡æ£€æŸ¥ | äººå·¥å®¡æ ¸ | å‘é‡ä¸€è‡´æ€§ | è‡ªåŠ¨åŒ– |

---

### 9.3 æœåŠ¡ç»ˆæç›®æ ‡

**æ¯é¢˜ + å‘é‡åŒ– + LLM = é«˜è´¨é‡é¢˜ç›®ç”Ÿæˆç³»ç»Ÿ**

```
æ¯é¢˜Schema â†’ å‘é‡åŒ– â†’ çº¦æŸç©ºé—´ â†’ LLMç”Ÿæˆ â†’ å‘é‡éªŒè¯ â†’ å…¥åº“
     â†‘                                              â†“
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åé¦ˆä¼˜åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®åˆ›æ–°**ï¼š
- **ç”Ÿæˆå‰æ£€æŸ¥**ï¼šé¿å…é‡å¤
- **ç”Ÿæˆä¸­çº¦æŸ**ï¼šä¿æŒè´¨é‡
- **ç”ŸæˆåéªŒè¯**ï¼šç¡®ä¿ä¸€è‡´

---

### 9.4 ä¸‹ä¸€æ­¥é‡ç‚¹

1. **å®Œæˆå‘é‡åŒ–**ï¼ˆ50å°æ—¶ï¼‰
2. **èšç±»åˆ†æ**ï¼ˆå‘ç°é¢˜ç›®å…³ç³»ï¼‰
3. **å˜æ¢ç®—å­è®¾è®¡**ï¼ˆè§„åˆ™åŒ–ç”Ÿæˆï¼‰
4. **LLMé›†æˆå®éªŒ**ï¼ˆç”Ÿæˆæµ‹è¯•ï¼‰
5. **è®ºæ–‡æ’°å†™**ï¼ˆç›®æ ‡ï¼šACM SIGCSE 2026ï¼‰

---

## 10. Q&A é¢„æœŸé—®é¢˜

**Q1: ä¸ºä»€ä¹ˆå‘é‡æ˜¯1024ç»´ï¼Ÿ**  
A: Qwen text-embedding-v3 API å›ºå®šè¾“å‡ºï¼Œä¸šç•Œæ ‡å‡†ç»´åº¦ã€‚

**Q2: å¦‚ä½•ä¿è¯å‘é‡è´¨é‡ï¼Ÿ**  
A: å®éªŒéªŒè¯ç›¸ä¼¼é¢˜ç›¸ä¼¼åº¦é«˜ï¼ˆ0.80+ï¼‰ï¼Œä¸ç›¸å…³é¢˜ä½ï¼ˆ<0.5ï¼‰ã€‚

**Q3: å‘é‡åŒ–ä¸LLMç”Ÿæˆçš„å…³ç³»ï¼Ÿ**  
A: å‘é‡ç”¨äº"è´¨é‡æ§åˆ¶"ï¼Œä¸æ˜¯æ›¿ä»£LLMï¼Œè€Œæ˜¯çº¦æŸLLMã€‚

**Q4: èƒ½å¦ç›´æ¥ä»å‘é‡åæ¨é¢˜ç›®ï¼Ÿ**  
A: ä¸èƒ½ç›´æ¥åæ¨ï¼Œä½†å¯æ‰¾åˆ°æœ€ç›¸ä¼¼çš„Schemaä½œä¸ºæ¨¡æ¿ã€‚

**Q5: å•†ä¸šåŒ–å¯èƒ½æ€§ï¼Ÿ**  
A: å¯é›†æˆåˆ°æ•™è‚²å¹³å°ï¼Œæä¾›"ä¸€é”®ç”Ÿæˆç»ƒä¹ é¢˜"åŠŸèƒ½ã€‚

---

**æŠ¥å‘Šå®Œæ¯•ï¼Œè¯·è€å¸ˆå’ŒåŒå­¦æ‰¹è¯„æŒ‡æ­£ï¼** ğŸ‰

---

## é™„å½•ï¼šæ•°æ®æ–‡ä»¶æ¸…å•

```
output/presentation/
â”œâ”€â”€ sample_embeddings.json          # å‰5é¢˜å®Œæ•´å‘é‡ (158.6 KB)
â”œâ”€â”€ full_embeddings.json            # å…¨éƒ¨39é¢˜å‘é‡ (1.2 MB)
â”œâ”€â”€ embeddings_summary.json         # ç»Ÿè®¡æ‘˜è¦ (14.0 KB)
â”œâ”€â”€ visualization_data.json         # å¯è§†åŒ–æ•°æ® (3.4 KB)
â””â”€â”€ figures/                        # å›¾è¡¨ï¼ˆå¾…ç”Ÿæˆï¼‰
    â”œâ”€â”€ similarity_heatmap.png
    â”œâ”€â”€ norm_distribution.png
    â”œâ”€â”€ dimension_distribution.png
    â”œâ”€â”€ top_similar_pairs.png
    â””â”€â”€ statistics_table.png
```
