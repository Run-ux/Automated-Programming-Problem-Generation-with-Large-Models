"""
å¯¼å‡ºå®Œæ•´çš„ embedding å‘é‡ä¸º JSON æ ¼å¼ï¼Œç”¨äºŽç»„ä¼šå±•ç¤º
æ³¨æ„ï¼šå®Œæ•´çš„1024ç»´å‘é‡ä¼šå¯¼è‡´æ–‡ä»¶å¾ˆå¤§ï¼Œå»ºè®®æŒ‰éœ€å¯¼å‡º
"""
import numpy as np
import json
from pathlib import Path

def export_full_embeddings(npz_file="output/schema_embeddings.npz", 
                           output_dir="output/presentation"):
    """
    å¯¼å‡ºå®Œæ•´çš„ embedding æ•°æ®ä¸ºå¤šç§æ ¼å¼
    
    è¾“å‡ºæ–‡ä»¶ï¼š
    1. full_embeddings.json - åŒ…å«æ‰€æœ‰é¢˜ç›®çš„å®Œæ•´1024ç»´å‘é‡ (è¾ƒå¤§)
    2. sample_embeddings.json - å‰5ä¸ªé¢˜ç›®çš„å®Œæ•´å‘é‡ (ç”¨äºŽå±•ç¤º)
    3. embeddings_summary.json - ç»Ÿè®¡æ‘˜è¦å’Œå¯è§†åŒ–æ•°æ®
    """
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    print("ðŸ“Š å¯¼å‡ºå®Œæ•´ Embedding æ•°æ®ç”¨äºŽç»„ä¼šå±•ç¤º")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    data = np.load(npz_file, allow_pickle=True)
    embeddings = data['embeddings']
    metadata = data['metadata']
    
    total = len(embeddings)
    dim = embeddings.shape[1]
    
    print(f"\nðŸ“ æ•°æ®æ¦‚è§ˆ:")
    print(f"   æ€»é¢˜ç›®æ•°: {total}")
    print(f"   å‘é‡ç»´åº¦: {dim}")
    print(f"   æ•°æ®å¤§å°: {embeddings.nbytes / 1024 / 1024:.2f} MB")
    
    # ===== 1. å¯¼å‡ºå‰5ä¸ªé¢˜ç›®çš„å®Œæ•´å‘é‡ï¼ˆç”¨äºŽPPTå±•ç¤ºï¼‰ =====
    print(f"\nðŸ“ æ­£åœ¨å¯¼å‡ºæ ·æœ¬æ•°æ® (å‰5ä¸ªé¢˜ç›®)...")
    sample_data = {
        "description": "LeetCodeé¢˜ç›®Schemaçš„Embeddingå‘é‡è¡¨ç¤º",
        "model": "Qwen text-embedding-v3",
        "dimension": int(dim),
        "sample_size": min(5, total),
        "schemas": []
    }
    
    for i in range(min(5, total)):
        schema_item = {
            "index": int(metadata[i].get('index', i)),
            "title": metadata[i].get('title', 'Unknown'),
            "slug": metadata[i].get('slug', ''),
            "difficulty": metadata[i].get('difficulty', 'Unknown'),
            "embedding_vector": embeddings[i].tolist(),  # å®Œæ•´çš„1024ç»´
            "statistics": {
                "min": float(embeddings[i].min()),
                "max": float(embeddings[i].max()),
                "mean": float(embeddings[i].mean()),
                "std": float(embeddings[i].std()),
                "norm": float(np.linalg.norm(embeddings[i])),
                "non_zero_count": int(np.count_nonzero(embeddings[i]))
            }
        }
        sample_data["schemas"].append(schema_item)
    
    sample_file = output_path / "sample_embeddings.json"
    with open(sample_file, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… å·²ä¿å­˜: {sample_file}")
    print(f"   æ–‡ä»¶å¤§å°: {sample_file.stat().st_size / 1024:.1f} KB")
    
    # ===== 2. å¯¼å‡ºç»Ÿè®¡æ‘˜è¦ï¼ˆç”¨äºŽå›¾è¡¨å±•ç¤ºï¼‰ =====
    print(f"\nðŸ“Š æ­£åœ¨ç”Ÿæˆç»Ÿè®¡æ‘˜è¦...")
    
    # è®¡ç®—æ‰€æœ‰å‘é‡çš„ç»Ÿè®¡ä¿¡æ¯
    all_stats = {
        "overall": {
            "total_schemas": int(total),
            "embedding_dimension": int(dim),
            "value_range": {
                "min": float(embeddings.min()),
                "max": float(embeddings.max())
            },
            "mean_across_all": float(embeddings.mean()),
            "std_across_all": float(embeddings.std())
        },
        "per_schema_statistics": []
    }
    
    # æ¯ä¸ªé¢˜ç›®çš„ç»Ÿè®¡
    for i in range(total):
        stat = {
            "index": int(metadata[i].get('index', i)),
            "title": metadata[i].get('title', 'Unknown'),
            "slug": metadata[i].get('slug', ''),
            "min": float(embeddings[i].min()),
            "max": float(embeddings[i].max()),
            "mean": float(embeddings[i].mean()),
            "std": float(embeddings[i].std()),
            "norm": float(np.linalg.norm(embeddings[i]))
        }
        all_stats["per_schema_statistics"].append(stat)
    
    # æ·»åŠ ç›¸ä¼¼åº¦çŸ©é˜µæ ·æœ¬ï¼ˆå‰10ä¸ªé¢˜ç›®ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼‰
    if total >= 2:
        print(f"   è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µæ ·æœ¬...")
        n_sample = min(10, total)
        from sklearn.metrics.pairwise import cosine_similarity
        
        sample_embeddings = embeddings[:n_sample]
        sim_matrix = cosine_similarity(sample_embeddings)
        
        all_stats["similarity_matrix_sample"] = {
            "description": "å‰10ä¸ªé¢˜ç›®ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦",
            "size": int(n_sample),
            "titles": [metadata[i].get('title', 'Unknown') for i in range(n_sample)],
            "matrix": sim_matrix.tolist()
        }
    
    summary_file = output_path / "embeddings_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(all_stats, f, ensure_ascii=False, indent=2)
    print(f"   âœ… å·²ä¿å­˜: {summary_file}")
    print(f"   æ–‡ä»¶å¤§å°: {summary_file.stat().st_size / 1024:.1f} KB")
    
    # ===== 3. å¯é€‰ï¼šå¯¼å‡ºæ‰€æœ‰é¢˜ç›®çš„å®Œæ•´å‘é‡ =====
    print(f"\nâ“ æ˜¯å¦å¯¼å‡ºæ‰€æœ‰ {total} ä¸ªé¢˜ç›®çš„å®Œæ•´å‘é‡ï¼Ÿ")
    print(f"   é¢„ä¼°æ–‡ä»¶å¤§å°: {total * dim * 8 / 1024 / 1024 * 1.5:.1f} MB")
    
    choice = input("   è¾“å…¥ y å¯¼å‡ºï¼Œå…¶ä»–é”®è·³è¿‡: ").strip().lower()
    
    if choice == 'y':
        print(f"\nðŸ“¦ æ­£åœ¨å¯¼å‡ºæ‰€æœ‰é¢˜ç›®çš„å®Œæ•´å‘é‡...")
        full_data = {
            "description": "æ‰€æœ‰LeetCodeé¢˜ç›®Schemaçš„å®Œæ•´Embeddingå‘é‡",
            "model": "Qwen text-embedding-v3",
            "dimension": int(dim),
            "total_schemas": int(total),
            "schemas": []
        }
        
        for i in range(total):
            schema_item = {
                "index": int(metadata[i].get('index', i)),
                "title": metadata[i].get('title', 'Unknown'),
                "slug": metadata[i].get('slug', ''),
                "embedding_vector": embeddings[i].tolist()
            }
            full_data["schemas"].append(schema_item)
            
            if (i + 1) % 100 == 0:
                print(f"   å¤„ç†è¿›åº¦: {i+1}/{total}")
        
        full_file = output_path / "full_embeddings.json"
        with open(full_file, 'w', encoding='utf-8') as f:
            json.dump(full_data, f, ensure_ascii=False, indent=2)
        print(f"   âœ… å·²ä¿å­˜: {full_file}")
        print(f"   æ–‡ä»¶å¤§å°: {full_file.stat().st_size / 1024 / 1024:.1f} MB")
    
    # ===== 4. ç”Ÿæˆå±•ç¤ºç”¨çš„å¯è§†åŒ–æ•°æ® =====
    print(f"\nðŸ“ˆ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æ•°æ®...")
    
    viz_data = {
        "description": "ç”¨äºŽç»„ä¼šPPTçš„å¯è§†åŒ–æ•°æ®",
        "dimension_distribution": {
            "description": "æ¯ä¸ªç»´åº¦çš„å€¼åˆ†å¸ƒç»Ÿè®¡",
            "dimensions": list(range(min(20, dim))),  # åªå–å‰20ç»´ä½œä¸ºç¤ºä¾‹
            "means": [float(embeddings[:, i].mean()) for i in range(min(20, dim))],
            "stds": [float(embeddings[:, i].std()) for i in range(min(20, dim))]
        },
        "norm_distribution": {
            "description": "æ‰€æœ‰é¢˜ç›®çš„å‘é‡æ¨¡é•¿åˆ†å¸ƒ",
            "norms": [float(np.linalg.norm(embeddings[i])) for i in range(total)]
        },
        "top_similar_pairs": []
    }
    
    # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„5å¯¹é¢˜ç›®
    if total >= 2:
        print(f"   å¯»æ‰¾æœ€ç›¸ä¼¼çš„é¢˜ç›®å¯¹...")
        from sklearn.metrics.pairwise import cosine_similarity
        
        sim_matrix = cosine_similarity(embeddings)
        np.fill_diagonal(sim_matrix, -1)  # æŽ’é™¤è‡ªå·±
        
        # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„5å¯¹
        flat_indices = np.argsort(sim_matrix.ravel())[-5:][::-1]
        for idx in flat_indices:
            i, j = np.unravel_index(idx, sim_matrix.shape)
            if i < j:  # é¿å…é‡å¤
                pair = {
                    "schema1": {
                        "index": int(i),
                        "title": metadata[i].get('title', 'Unknown')
                    },
                    "schema2": {
                        "index": int(j),
                        "title": metadata[j].get('title', 'Unknown')
                    },
                    "similarity": float(sim_matrix[i, j])
                }
                viz_data["top_similar_pairs"].append(pair)
    
    viz_file = output_path / "visualization_data.json"
    with open(viz_file, 'w', encoding='utf-8') as f:
        json.dump(viz_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ… å·²ä¿å­˜: {viz_file}")
    print(f"   æ–‡ä»¶å¤§å°: {viz_file.stat().st_size / 1024:.1f} KB")
    
    # ===== æ€»ç»“ =====
    print("\n" + "=" * 60)
    print("âœ… å¯¼å‡ºå®Œæˆï¼ç»„ä¼šå±•ç¤ºæ–‡ä»¶å·²å‡†å¤‡å°±ç»ª")
    print("=" * 60)
    print(f"\nðŸ“‚ è¾“å‡ºç›®å½•: {output_path.absolute()}")
    print(f"\nðŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"   1. sample_embeddings.json")
    print(f"      â†’ å‰5ä¸ªé¢˜ç›®çš„å®Œæ•´1024ç»´å‘é‡ï¼ˆç”¨äºŽè¯¦ç»†å±•ç¤ºï¼‰")
    print(f"   2. embeddings_summary.json")
    print(f"      â†’ æ‰€æœ‰é¢˜ç›®çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºŽè¡¨æ ¼å±•ç¤ºï¼‰")
    print(f"   3. visualization_data.json")
    print(f"      â†’ å¯è§†åŒ–æ•°æ®ï¼ˆç”¨äºŽå›¾è¡¨ï¼‰")
    if choice == 'y':
        print(f"   4. full_embeddings.json")
        print(f"      â†’ æ‰€æœ‰é¢˜ç›®çš„å®Œæ•´å‘é‡ï¼ˆç”¨äºŽå¤‡ä»½/å®Œæ•´å±•ç¤ºï¼‰")
    
    print(f"\nðŸ’¡ ç»„ä¼šå±•ç¤ºå»ºè®®:")
    print(f"   - ç”¨ sample_embeddings.json å±•ç¤ºå…·ä½“ä¾‹å­")
    print(f"   - ç”¨ embeddings_summary.json åˆ¶ä½œç»Ÿè®¡è¡¨æ ¼")
    print(f"   - ç”¨ visualization_data.json ç»˜åˆ¶å›¾è¡¨")
    print(f"   - è¿™äº›JSONæ–‡ä»¶å¯ä»¥ç›´æŽ¥ç”¨Python/Excel/åœ¨çº¿å·¥å…·æ‰“å¼€")
    print("=" * 60)

if __name__ == "__main__":
    export_full_embeddings()
