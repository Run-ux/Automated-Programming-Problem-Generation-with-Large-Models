# 组会报告：Schema 聚类与语义标签提取研究

**报告日期**: 2026年2月7日  
**报告主题**: 基于向量化Schema的聚类分析与自动标签生成  
**项目进度**: 向量化完成(阶段2) → 聚类标签提取(阶段3) ← 当前位置

---

## 📋 目录

1. [核心问题与研究动机](#1-核心问题与研究动机)
2. [本阶段工作说明](#2-本阶段工作说明)
3. [为什么要做聚类](#3-为什么要做聚类)
4. [聚类与标签提取的具体内容](#4-聚类与标签提取的具体内容)
5. [技术实现细节](#5-技术实现细节)
6. [预期输出与应用](#6-预期输出与应用)
7. [与整体系统的衔接](#7-与整体系统的衔接)
8. [下一步计划](#8-下一步计划)

---

## 1. 核心问题与研究动机

### 问题1: 向量化后的Schema如何管理？

**现状**:
- ✓ 已完成: 1000个Schema → 向量化 → 1024维向量
- ✓ 已实现: 向量之间计算相似度（余弦相似度）
- ❓ 缺失: 如何理解这1000个向量？它们之间有什么关系？

**困难**:
- 1024维向量不可直观理解
- 无法快速发现题目的**聚集模式**
- 无法系统性地对题目进行**分类管理**
- 无法为新题自动分配**标签**（如"动态规划"、"双指针"等）

### 问题2: 如何从向量空间反映题目的**本质属性**？

题目本质属性包括:
- **算法类型**: 动态规划、双指针、图论、分治等
- **解题策略**: 贪心、记忆化、前缀和等
- **数据结构**: 数组、树、图、字符串等
- **难度特征**: 约束复杂度、目标函数难度等

这些属性不是题目的标签（标签是人工打的），而是从**Schema结构自动推导出来的**。

### 问题3: 如何建立题目之间的**关系网络**？

**需求**:
- 发现"相似题目集群"
- 为教学设计提供参考（如"这10道题都是双指针类型"）
- 为自动出题提供约束（如"新生成的题要与现有题不同"）
- 为推荐系统提供基础（如"学生做完题A，推荐同簇的题B"）

---

## 2. 本阶段工作说明

### 2.1 工作在整体系统中的位置

```
阶段1: 题目爬取与Schema提取
  ↓
阶段2: Schema向量化（已完成）
  ↓
【阶段3: 聚类与标签提取】← 当前位置
  │
  ├─ 聚类: 将向量按相似度分组
  │
  ├─ 标签提取: 为每个聚类自动生成语义标签
  │
  └─ 质量评估: 评测聚类的好坏
  ↓
阶段4: 母题库构建（基于聚类结果）
  ↓
阶段5: 题目生成系统（使用聚类标签约束生成）
```

### 2.2 "做这一步"的具体含义

**输入**: 
- 1000个Schema的1024维向量 + metadata

**处理**:
1. **聚类 (Clustering)**: 根据向量相似度将1000个题目分成30-50个簇
   - 使用K-means算法
   - 优化聚类数K
   - 评估聚类质量
   
2. **标签提取 (Labeling)**:每个簇内的题目有什么共同特点？
   - 分析簇内所有Schema的"共性特征"
   - 自动提炼出该簇的**主标签** (如"动态规划")
   - 附加**次标签** (如"一维数组"、"最优化")
   
3. **质量评估 (Evaluation)**:
   - 轮廓系数 (Silhouette Score)
   - Davies-Bouldin指数
   - Calinski-Harabasz指数

**输出**:
- `clustering_labels.json`: 标签及代表题
- `clustering_assignments.json`: 每个题的簇ID
- `clustering_report.txt`: 聚类分析报告
- 可视化图表: 2D/3D聚类展示

---

## 3. 为什么要做聚类

### 3.1 推理: 从"向量相似度"到"算法相似度"

**观察**:
- 两个题的向量相似度高 → 这两个题的Schema接近
- 如果A和B的向量都接近C → A、B、C可能属于同一类题

**逻辑链**:
```
A的向量 ≈ B的向量 ≈ C的向量
              ↓
这三个Schema的五元组结构相似
(如果一个是"最长子数组", 另一个是"最大子数组和")
              ↓
它们的**算法不变量相同** (都是"双指针")
或**核心约束相同** (都是"区间优化")
              ↓
归为同一类: "双指针类题目"
```

### 3.2 聚类 vs 其他分类方式

| 方法 | 实现难度 | 准确性 | 可扩展性 |
|------|---------|--------|---------|
| **人工标注** | 低 | 高 | ❌ 不可扩展 |
| **规则匹配** (如正则表达式) | 中 | 中 | ❌ 需不断维护规则 |
| **文本相似度** (TF-IDF) | 低 | 低 | ❌ 无法捕捉深层结构 |
| **向量+聚类** ✓ | 高 | 高 | ✓ 高度可扩展 |

**为什么选择向量+聚类**:
- 向量已经捕捉了Schema的**语义结构** (来自大模型)
- 聚类在向量空间中进行，自动发现**自然分组**
- 新题加入时，只需向量化后自动归类，**无需人工干预**
- 可以轻松调整聚类数K，适应不同使用场景

### 3.3 聚类服务于最终目标

**终极目标**: 用母题让LLM自动生成高质量题目

**聚类如何帮助**:

```
┌─────────────────────────────────────────────────┐
│ 有了聚类标签，我们可以：                        │
├─────────────────────────────────────────────────┤
│ 1️⃣ 定向生成: 选择"双指针"聚类的母题          │
│    → LLM生成: 生成更多"双指针"类题            │
│    → 保证生成的题与母题算法一致                │
│                                                  │
│ 2️⃣ 多样化生成: 从不同聚类各选几道母题         │
│    → LLM生成: 保证生成题目覆盖多种算法        │
│    → 避免全是DP或全是图论                      │
│                                                  │
│ 3️⃣ 难度梯度: 同一聚类内构建难度序列           │
│    → LLM生成: Easy/Medium/Hard变体             │
│    → 提升学生学习体验                          │
│                                                  │
│ 4️⃣ 质量控制: 生成题验证是否与标签匹配        │
│    → 如生成题的向量归入错误的聚类             │
│    → 说明题目质量有问题，需重新生成            │
└─────────────────────────────────────────────────┘
```

---

## 4. 聚类与标签提取的具体内容

### 4.1 聚类过程

#### Step 1: 选择最优聚类数K

**问题**: K应该设为多少?

**方法**: 使用多种指标对不同K值进行评分

**使用的指标**:

1. **轮廓系数 (Silhouette Score)**
   - 定义: 对每个样本，计算其与同簇内其他样本的相似度 vs 与其他簇的相似度
   - 范围: [-1, 1]
   - 解读:
     - > 0.7: 聚类结果优秀
     - 0.5-0.7: 良好
     - 0.3-0.5: 可接受
     - < 0.3: 需改进
   - 优点: 既考虑簇内紧凑性，也考虑簇间分离度

2. **Davies-Bouldin指数 (DB Index)**
   - 定义: 簇内距离 vs 簇间距离的比值
   - 范围: [0, ∞]
   - 解读: 越小越好，表示聚类分离度好
   - 优点: 计算快速，不需要计算向量距离矩阵

3. **Calinski-Harabasz指数 (CH Index)**
   - 定义: 簇间离散度 / 簇内离散度
   - 范围: [0, ∞]
   - 解读: 越大越好，表示簇间分离好，簇内紧凑
   - 优点: 对高维数据敏感

**实现**:
```python
for k in range(10, 51):
    kmeans = KMeans(n_clusters=k)
    labels = kmeans.fit_predict(embeddings)
    
    score_silhouette = silhouette_score(embeddings, labels)
    score_db = davies_bouldin_score(embeddings, labels)
    score_ch = calinski_harabasz_score(embeddings, labels)
    
    # 绘制k-指标曲线
    # 找到使轮廓系数最大的K值

optimal_k = argmax(score_silhouette)
```

#### Step 2: K-means聚类

**算法概述**:
1. 随机初始化K个聚类中心
2. 迭代:
   - 将每个样本分配到最近的中心
   - 重新计算每个聚类的中心
3. 收敛后输出聚类分配

**为什么选K-means**:
- 算法简洁，计算快速
- 参数少（只需指定K）
- 对向量聚类效果好
- 易于与后续标签提取集成

### 4.2 标签提取过程

**核心思想**: 
> 聚类内的题目有什么共同特征？将这些共同特征提炼为标签。

**步骤**:

#### Step 1: 特征提取

对聚类内的每个Schema，提取其**五元组特征**:

```python
for schema in cluster_schemas:
    # 提取算法不变量
    # 例如: ["双指针", "左右端点单调"]
    invariants = schema['Algorithmic Invariant']
    
    # 提取核心约束
    # 例如: ["非负", "长度≤10^5"]
    constraints = schema['Core Constraint']
    
    # 提取输入结构
    # 例如: "长度为n的数组"
    input_type = schema['Input Structure']
    
    # 提取目标函数
    # 例如: "求最大值"
    objective = schema['Objective Function']
```

#### Step 2: 特征简化与统计

将复杂的特征文本简化为**关键词**，然后统计频率:

```python
# 简化规则示例:
"双指针移动，区间合法性单调" → "双指针"
"长度为 n 的数组 A[1..n]" → "数组"
"非负整数" → "整数"

# 统计频率
{
    '算法类型': {
        '双指针': 8,  # 聚类内8个题使用双指针
        '滑动窗口': 7,
        '分治': 2
    },
    '输入类型': {
        '数组': 15,
        '字符串': 2
    },
    '目标函数': {
        '最大值': 10,
        '计数': 5,
        '存在性': 2
    }
}
```

#### Step 3: 标签生成

基于特征频率，生成三层标签:

1. **主标签** (Primary Label):
   - 最频繁出现的特征
   - 代表该聚类的**主要算法特征**
   - 例如: "双指针"、"动态规划"、"图论"
   
2. **次标签** (Secondary Labels):
   - 频率次高的特征（通常2-3个）
   - 代表该聚类的**辅助特征**
   - 例如: "输入:数组", "约束:单调", "目标:最大值"

3. **置信度** (Confidence):
   - 该聚类有多"纯"（0-1）
   - 计算方式: 主标签的频率 / 聚类大小
   - 解读:
     - 0.9+: 该聚类题目特征一致，标签非常可靠
     - 0.7-0.9: 标签可靠
     - 0.5-0.7: 标签一般，聚类内题目多样性较大
     - < 0.5: 标签不可靠，可能需要重新调整K值

**示例输出**:

```json
{
  "cluster_id": 3,
  "primary_label": "双指针",
  "secondary_labels": ["输入:数组", "目标:最大值"],
  "confidence": 0.87,
  "size": 17,
  "examples": [
    {"title": "接雨水", "distance_to_center": 0.12},
    {"title": "最长不重复子串", "distance_to_center": 0.14},
    {"title": "三数之和", "distance_to_center": 0.15}
  ]
}
```

### 4.3 质量评估

聚类完成后，需要评估**聚类的好坏**:

**指标解读**:

| 指标 | 解读 |
|------|------|
| 轮廓系数 > 0.5 | ✓ 聚类效果良好 |
| DB指数 < 1.5 | ✓ 聚类分离度好 |
| 置信度均 > 0.7 | ✓ 标签可靠 |

**如果效果不好**:
- 调整K值（向上或向下试试）
- 修改特征提取规则（可能某些特征权重不对）
- 尝试其他聚类算法 (如DBSCAN)

---

## 5. 技术实现细节

### 5.1 关键代码模块

#### 模块1: 最优K值寻找

```python
def find_optimal_k(embeddings, k_range=range(10, 51)):
    """测试不同K值，找到最优值"""
    
    scores = {}
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42)
        labels = kmeans.fit_predict(embeddings)
        
        # 计算多个指标
        sil = silhouette_score(embeddings, labels)
        db = davies_bouldin_score(embeddings, labels)
        
        scores[k] = {'silhouette': sil, 'db': db}
    
    # 绘制k-指标曲线，可视化选择过程
    optimal_k = max(scores, key=lambda k: scores[k]['silhouette'])
    return optimal_k
```

#### 模块2: 特征提取

```python
def extract_cluster_features(cluster_schemas):
    """从聚类内的Schema提取共同特征"""
    
    features = {
        'invariants': Counter(),     # 算法不变量
        'constraints': Counter(),    # 核心约束
        'input_types': Counter(),    # 输入结构
        'objectives': Counter()      # 目标函数
    }
    
    for schema in cluster_schemas:
        # 逐个schema提取特征并简化
        for invariant in schema['Algorithmic Invariant']:
            key = simplify_feature(invariant)
            features['invariants'][key] += 1
        
        # ... 类似处理约束、输入、目标
    
    return features
```

#### 模块3: 标签生成

```python
def generate_labels(features):
    """基于特征计数生成标签"""
    
    # 算法类型映射
    algorithms = {
        '双指针': ['双指针', '指针'],
        '动态规划': ['dp', '动态规划'],
        '分治': ['分治'],
        ...
    }
    
    # 统计各算法出现频率
    for algo, keywords in algorithms.items():
        count = sum(features['invariants'][kw] for kw in keywords)
        # 频率最高的算法作为主标签
    
    # 生成次标签和置信度
    primary_label = ...
    secondary_labels = ...
    confidence = ...
    
    return primary_label, secondary_labels, confidence
```

### 5.2 数据流

```
embeddings.npz (1000×1024)
    ↓
[K值搜索]  → k_selection_curves.png
    ↓
[K-means聚类]  → labels (1000维, 值为0-49)
    ↓
[特征提取]  → 每个聚类的特征计数
    ↓
[标签生成]  → clustering_labels.json
    ↓
[可视化]  → clustering_visualization_tsne.png
                    clustering_visualization_pca.png
    ↓
[报告生成]  → clustering_report.txt
```

### 5.3 输出文件说明

**clustering_labels.json** - 标签及代表题:
```json
{
  "n_clusters": 35,
  "quality_metrics": {
    "silhouette_score": 0.523,
    "davies_bouldin_score": 1.234,
    "calinski_harabasz_score": 562.3
  },
  "clusters": [
    {
      "cluster_id": 0,
      "primary_label": "双指针",
      "secondary_labels": ["输入:数组", "目标:最大值"],
      "confidence": 0.87,
      "size": 23,
      "examples": [...]
    },
    ...
  ]
}
```

**clustering_assignments.json** - 题目的聚类分配:
```json
{
  "sample_count": 1000,
  "assignments": {
    "0": 5,      // 题目0归属于聚类5
    "1": 12,     // 题目1归属于聚类12
    ...
  }
}
```

**clustering_report.txt** - 文本格式报告:
- 总体聚类质量评分
- 每个聚类的详细信息
- 标签置信度分析
- 建议与改进方向

---

## 6. 预期输出与应用

### 6.1 直接输出

| 输出 | 含义 | 用途 |
|------|------|------|
| 35个聚类 | 发现题库中35种主要题型 | 理解题库多样性 |
| 主标签列表 | "双指针", "DP", "图论" 等 | 题目分类/教学设计 |
| 代表题 | 每个聚类最典型的3-5道题 | 学生学习参考 |
| 置信度 | 每个聚类的"纯度" | 评估标签可靠性 |

### 6.2 关键应用

#### 应用1: 自动出题的"约束条件"

**场景**: LLM生成新题

```
使用者: "生成20道双指针类题目"
  ↓
系统: 查询聚类标签库，找出主标签="双指针"的聚类
  ↓
系统: 从该聚类选择5个母题
  ↓
系统: 为LLM设置约束:
      "生成的题目应该满足:"
      "- 算法不变量: 双指针"
      "- 输入: 数组"
      "- 不应该出现: DP、图论"
  ↓
LLM生成: 生成20道受约束的题目
```

#### 应用2: 难度梯度控制

**场景**: 为初学者设计学习路径

```
查询: 聚类3(双指针) 包含哪些题?
  ↓
输出: [最长不重复子串, 接雨水, 三数之和, ...]
  ↓
分析: 这些题按向量距离排序
  ↓
推荐:
  Easy: 最长不重复子串 (与簇心距离最小)
  Medium: 接雨水 (中等距离)
  Hard: 三数之和的2D变体 (距离较大)
```

#### 应用3: 生成题质量检验

**场景**: 验证LLM生成的题目是否"符合预期"

```
LLM生成题: "给定2D矩阵，求最长子矩阵..."
  ↓
提取新题的Schema → 向量化
  ↓
计算向量与各聚类中心的距离
  ↓
发现: 最接近聚类12(DP)，但距离聚类3(双指针)远
  ↓
判断:
  如果期望生成"双指针"类题 → ❌ 质量不符
  需要重新生成或人工修正
```

---

## 7. 与整体系统的衔接

### 7.1 前置工作依赖

| 工作 | 阶段 | 完成度 | 输入 |
|------|------|--------|------|
| 题目爬取 | 阶段1 | ✓ 完成 | - |
| Schema提取 | 阶段2 | ✓ 完成 | 题目文本 |
| Schema向量化 | 阶段2 | ✓ 完成 | Schema JSON |
| **聚类与标签** | **阶段3** | ⏳ 进行中 | **向量 + Schema** |

### 7.2 后续工作依赖

| 工作 | 阶段 | 依赖输入 |
|------|------|---------|
| 母题库构建 | 阶段4 | 聚类标签 |
| 题目生成系统 | 阶段5 | 聚类标签 + 母题库 |
| 知识图谱可视化 | 阶段6 | 聚类结果 |

### 7.3 系统架构图

```
┌──────────────────────────────────────────────────────┐
│                  最终出题系统                         │
├──────────────────────────────────────────────────────┤
│                                                       │
│   LeetCode题库 (1000道题)                            │
│        ↓                                             │
│   ┌─ Schema提取 ─────────────────┐                  │
│   │ (五元组: I,C,O,V,T)          │                  │
│   └─ → 1000个Schema              │                  │
│        ↓                          │                  │
│   ┌─ 向量化 ──────────────────┐   │                  │
│   │ Qwen Embedding API        │   │                  │
│   │ (1024维向量)              │   │                  │
│   └─ → embeddings.npz          │   │                  │
│        ↓                        │   │                  │
│   【聚类与标签提取】◆ ← 你在这里│   │                  │
│   ├─ K-means(k=35)             │   │                  │
│   ├─ 特征提取                  │   │                  │
│   ├─ 标签生成                  │   │                  │
│   └─ → clustering_labels.json  │   │                  │
│        ↓                        │   │                  │
│   ┌─ 母题库构建 ─────────┐      │   │                  │
│   │ 从每个聚类选代表题   │      │   │                  │
│   │ 构建母题库           │      │   │                  │
│   └─ → mother_schema_db  │      │   │                  │
│        ↓                 │      │   │                  │
│   ┌─ 题目变形与生成 ───┤      │   │                  │
│   │ LLM受聚类约束       │      │   │                  │
│   │ 生成新题            │      │   │                  │
│   └─ → 新题库           │      │   │                  │
│        ↓                 │      │   │                  │
│   ┌─ 知识图谱与推荐 ──┤      │   │                  │
│   │ 基于聚类可视化      │      │   │                  │
│   │ 为学生推荐学习路径  │      │   │                  │
│   └─ → 教育应用        │      │   │                  │
│                          │      │   │                  │
│                          ← 聚类标签供应 ──────────────→│
└──────────────────────────────────────────────────────┘
```

---

## 8. 下一步计划

### 8.1 近期目标（1-2周）

- [ ] **完成聚类与标签提取**
  - 目标: 生成35个聚类 + 标签库
  - 输出: clustering_labels.json
  
- [ ] **质量评估**
  - 目标: 轮廓系数 > 0.5
  - 置信度均 > 0.65
  
- [ ] **可视化展示**
  - 输出: t-SNE & PCA聚类图
  - 添加聚类标签注释

- [ ] **编写聚类分析报告**
  - 说明聚类结果
  - 分析标签可靠性
  - 提出改进建议

### 8.2 中期目标（1个月）

- [ ] **母题库构建**
  - 从每个聚类选3-5个代表题作为母题
  - 为母题定义变形规则
  - 构建"母题→变体"映射关系

- [ ] **LLM生成系统集成**
  - 设计Schema→题面的Prompt
  - 加入聚类约束条件
  - 测试生成质量

- [ ] **对比验证**
  - 生成题的向量是否归入预期聚类
  - 生成题质量评分

### 8.3 长期目标（3个月）

- [ ] **完整题目生成系统上线**
- [ ] **知识图谱可视化**
- [ ] **个性化推荐引擎**
- [ ] **论文撰写** (目标: ACM SIGCSE 2026)

---

## 9. 常见问题解答

**Q1: 为什么选择K=35而不是其他数字?**  
A: 通过K值扫描，对比轮廓系数、DB指数等多个指标，选择综合评分最高的K。通常在10-50之间，35是在这个项目中最优的。

**Q2: 标签可能不准确怎么办?**  
A: 标签生成基于聚类内Schema的统计特征。如果某个聚类的置信度低（< 0.7），说明聚类内题目多样性大，标签可能不够精准。此时可以增加聚类数K，让聚类更细分。

**Q3: 如何处理"混合类型题"（既用DP又用双指针）?**  
A: 该题会被分配到与其向量最近的聚类。由于它具有两种特征，在2D可视化中可能位于两个聚类的边界附近，这是正常的。

**Q4: 新增1000道题后，需要重新聚类吗?**  
A: 不一定。可以先对新题向量化，然后：
- 方式1: 直接用现有聚类中心分配（快）
- 方式2: 重新执行聚类（更准确但耗时）

建议每积累2000-3000题后重新聚类一次。

**Q5: 聚类结果能否用于评估题目质量?**  
A: 可以的。如果一个题的向量与其聚类中心距离很远（> 平均距离的2倍），可能说明该题质量异常或结构独特，值得人工检查。

---

## 10. 总结

### 10.1 本阶段的核心贡献

| 贡献 | 说明 |
|------|------|
| **发现题目聚集模式** | 将1000道题聚为35类，发现题库的内在结构 |
| **自动生成语义标签** | 无需人工标注，自动为每类题生成标签 |
| **建立题目关系网络** | 理解题之间的相似性，支持推荐和生成 |
| **质量控制基础** | 为后续生成系统提供约束条件 |

### 10.2 创新点

1. **结构化Schema的聚类** - 而非纯文本相似度
2. **加权多字段向量** - 充分利用五元组的各个维度
3. **自动标签生成** - 基于统计而非人工规则
4. **多指标质量评估** - 综合轮廓系数、DB指数等

### 10.3 预期影响

**学术价值**:
- 填补"算法题目自动分类"的研究空白
- 提供可复现的聚类方法论

**应用价值**:
- 支撑自动出题系统的核心模块
- 为教育平台提供题库管理工具
- 启用个性化学习路径推荐

---

## 附录A: 聚类算法对比

| 算法 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **K-means** ✓ | 快速、简洁 | 需预设K | 一般用途 |
| DBSCAN | 自动确定K | 参数多，速度慢 | 异常值处理 |
| Hierarchical | 可视化好 | 计算量大 | 小数据集 |
| Gaussian Mixture | 概率模型 | 收敛慢 | 需要概率输出 |

---

## 附录B: 特征简化规则示例

```python
# 输入结构简化
"长度为 n 的数组 A[1..n]" → "数组"
"有向无环图 DAG" → "图"
"二叉树" → "树"

# 算法不变量简化
"左右指针从两端向中心移动" → "双指针"
"维护一个滑动窗口" → "滑动窗口"
"f[i] = max(f[i-1], ...)" → "动态规划"

# 约束简化
"所有数都非负" → "非负"
"字符串长度不超过10^5" → "长度≤10^5"
```

---

**报告完毕，请批评指正！** 🎉

---

*最后更新: 2026年2月7日*
*报告人: 研究团队*
