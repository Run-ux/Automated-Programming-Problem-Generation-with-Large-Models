"""
æŸ¥çœ‹å’Œæ£€æŸ¥ schema_embeddings.npz æ–‡ä»¶çš„å†…å®¹
"""
import numpy as np
from pathlib import Path
import json

def view_embeddings(file_path="output/schema_embeddings.npz"):
    """æŸ¥çœ‹embeddingæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
    
    file_path = Path(file_path)
    
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        print(f"   è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Œå½“å‰å·¥ä½œç›®å½•: {Path.cwd()}")
        return
    
    print("="*60)
    print("ğŸ“Š Schema Embeddings æ–‡ä»¶æŸ¥çœ‹å™¨")
    print("="*60)
    
    # æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    file_size = file_path.stat().st_size
    print(f"\nğŸ“ æ–‡ä»¶ä¿¡æ¯:")
    print(f"   è·¯å¾„: {file_path.absolute()}")
    print(f"   å¤§å°: {file_size / 1024:.2f} KB ({file_size / 1024 / 1024:.2f} MB)")
    print(f"   ä¿®æ”¹æ—¶é—´: {file_path.stat().st_mtime}")
    
    # åŠ è½½æ•°æ®
    try:
        data = np.load(file_path, allow_pickle=True)
        print(f"\nâœ… æ–‡ä»¶åŠ è½½æˆåŠŸ!")
        
        # æ˜¾ç¤ºåŒ…å«çš„æ•°ç»„
        print(f"\nğŸ“¦ åŒ…å«çš„æ•°æ®:")
        for key in data.files:
            print(f"   - {key}")
        
        # æ˜¾ç¤ºembeddingä¿¡æ¯
        if 'embeddings' in data:
            embeddings = data['embeddings']
            print(f"\nğŸ¯ Embeddings è¯¦æƒ…:")
            print(f"   æ•°é‡: {len(embeddings)} ä¸ªSchema")
            print(f"   ç»´åº¦: {embeddings.shape[1]} ç»´å‘é‡")
            print(f"   æ•°æ®ç±»å‹: {embeddings.dtype}")
            print(f"   å†…å­˜å ç”¨: {embeddings.nbytes / 1024 / 1024:.2f} MB")
            print(f"   å‘é‡èŒƒå›´: [{embeddings.min():.4f}, {embeddings.max():.4f}]")
            
            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå‘é‡çš„æ ·æœ¬
            print(f"\nğŸ“ ç¬¬ä¸€ä¸ªSchemaçš„å‘é‡æ ·æœ¬ (å‰10ä¸ªå€¼):")
            print(f"   {embeddings[0][:10]}")
        
        # æ˜¾ç¤ºmetadataä¿¡æ¯
        if 'metadata' in data:
            metadata = data['metadata']
            print(f"\nğŸ“‹ Metadata è¯¦æƒ…:")
            print(f"   æ•°é‡: {len(metadata)} ä¸ªæ¡ç›®")
            
            # æ˜¾ç¤ºå‰5ä¸ªé¢˜ç›®
            print(f"\nğŸ† å·²å¤„ç†çš„Schema (å‰10ä¸ª):")
            for i, item in enumerate(metadata[:10]):
                title = item['title'] if isinstance(item, dict) else item.get('title', 'Unknown')
                print(f"   {i+1}. {title}")
            
            if len(metadata) > 10:
                print(f"   ... è¿˜æœ‰ {len(metadata) - 10} ä¸ª")
            
            # æ˜¾ç¤ºæœ€åå¤„ç†çš„å‡ ä¸ª
            if len(metadata) > 10:
                print(f"\nğŸ”„ æœ€è¿‘å¤„ç†çš„Schema (å5ä¸ª):")
                for i, item in enumerate(metadata[-5:], start=len(metadata)-4):
                    title = item['title'] if isinstance(item, dict) else item.get('title', 'Unknown')
                    print(f"   {i}. {title}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        if 'embeddings' in data:
            emb = data['embeddings']
            print(f"   å¹³å‡å€¼: {emb.mean():.6f}")
            print(f"   æ ‡å‡†å·®: {emb.std():.6f}")
            print(f"   ä¸­ä½æ•°: {np.median(emb):.6f}")
        
        # å®Œæˆåº¦
        if 'metadata' in data:
            total_expected = 1000  # ä»ä¹‹å‰çš„è¿›åº¦æ¡çœ‹åˆ°æ˜¯1000ä¸ª
            current = len(metadata)
            progress = current / total_expected * 100
            print(f"\nâ±ï¸  å¤„ç†è¿›åº¦:")
            print(f"   å·²å®Œæˆ: {current}/{total_expected} ({progress:.1f}%)")
            print(f"   å‰©ä½™: {total_expected - current} ä¸ª")
        
    except Exception as e:
        print(f"\nâŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*60)

def export_to_json(npz_file="output/schema_embeddings.npz", 
                   json_file="output/embeddings_preview.json"):
    """å¯¼å‡ºéƒ¨åˆ†æ•°æ®ä¸ºJSONæ ¼å¼ï¼Œæ–¹ä¾¿æŸ¥çœ‹"""
    
    try:
        data = np.load(npz_file, allow_pickle=True)
        
        preview = {
            "total_schemas": len(data['embeddings']),
            "embedding_dimension": data['embeddings'].shape[1],
            "schemas": []
        }
        
        # åªå¯¼å‡ºå‰10ä¸ªä½œä¸ºé¢„è§ˆ
        for i in range(min(10, len(data['metadata']))):
            item = {
                "index": int(data['metadata'][i].get('index', i)),
                "title": data['metadata'][i].get('title', 'Unknown'),
                "slug": data['metadata'][i].get('slug', ''),
                "embedding_sample": data['embeddings'][i][:10].tolist(),  # åªä¿å­˜å‰10ä¸ªå€¼
                "embedding_stats": {
                    "min": float(data['embeddings'][i].min()),
                    "max": float(data['embeddings'][i].max()),
                    "mean": float(data['embeddings'][i].mean())
                }
            }
            preview["schemas"].append(item)
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(preview, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²å¯¼å‡ºé¢„è§ˆæ•°æ®åˆ°: {json_file}")
        print(f"   ä½ å¯ä»¥ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€è¿™ä¸ªJSONæ–‡ä»¶æŸ¥çœ‹")
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

if __name__ == "__main__":
    print("\né€‰æ‹©æ“ä½œ:")
    print("1. æŸ¥çœ‹ embedding æ–‡ä»¶è¯¦æƒ…")
    print("2. å¯¼å‡ºä¸ºJSONæ ¼å¼ï¼ˆåªå¯¼å‡ºå‰10ä¸ªä½œä¸ºé¢„è§ˆï¼‰")
    print("3. ä¸¤è€…éƒ½æ‰§è¡Œ")
    
    choice = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice in ['1', '3']:
        view_embeddings()
    
    if choice in ['2', '3']:
        print()
        export_to_json()
